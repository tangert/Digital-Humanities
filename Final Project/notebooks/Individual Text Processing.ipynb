{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from itertools import chain, combinations\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import smart_open, simple_preprocess\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.level = logging.INFO  # ipython sometimes messes up the logging setup; restore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "Getting the data from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_df = pd.read_csv(\"../data/old-testament-verses.csv\")\n",
    "nt_df = pd.read_csv(\"../data/new-testament-verses.csv\")\n",
    "\n",
    "#rename from AyahText to VerseText\n",
    "q_df = pd.read_csv(\"../data/quran-verses.csv\")\n",
    "q_df.columns = ['DatabaseID', 'SuraID', 'VerseID', 'VerseText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(df):\n",
    "    return list(df[\"VerseText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stops = [w for w in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the stop words the most common words...?\n",
    "new_stops = ['hath', \"'s\",'an', 'let','behold', 'went','o','hast','thine','like','thing','things','quot','and', 'in', 'thou', 'thee', 'thy', 'unto', 'ye', 'said', 'saith', 'shall', 'shalt', 'yea', 'thereof']\n",
    "all_stops += new_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "regex = re.compile('[%s]' % re.escape(punctuation))\n",
    "\n",
    "def strip_punc(s):  # From Vinko's solution, with fix.\n",
    "    return regex.sub('', s)\n",
    "\n",
    "def clean_text(text):\n",
    "    # basic nlp clean up\n",
    "    lm = WordNetLemmatizer()\n",
    "    st = SnowballStemmer(\"english\")\n",
    "\n",
    "    base = [strip_punc(t).lower() for t in word_tokenize(text)\n",
    "            if t not in punctuation\n",
    "            and t.lower() not in all_stops]\n",
    "    \n",
    "    lemmatized = [lm.lemmatize(w) for w in base]\n",
    "#     stemmed = [st.stem(w) for w in lemmatized]\n",
    "    no_chars = [w for w in lemmatized if len(w) > 1]\n",
    "    \n",
    "    return no_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab preparation\n",
    "\n",
    "Constructing a holistic Doc2Vec model for all of the texts put together. Basically, this is just Word2Vec but tagging each word with which religion it belongs to (according to a probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(df):\n",
    "    vocab = []\n",
    "    for l in get_lines(df):\n",
    "        tokens = tokenize(l)\n",
    "        vocab += tokens\n",
    "    return set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shared(sets):\n",
    "    # Finds the intersection of all the input sets\n",
    "    return reduce((lambda set1,set2: set1&set2), sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sym_diffs(sets):\n",
    "    # Finds the symm etric difference of a list of sets\n",
    "    return reduce((lambda set1, set2: set1.symmetric_difference(set2)), sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_uniques(sets):\n",
    "    # Gets the unique elements in each set\n",
    "    # return a dictionary with labels of each\n",
    "    intersection = get_shared(sets)\n",
    "    sym_diffs = get_sym_diffs(sets)\n",
    "    return sym_diffs - intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_vocabs(vocabs_dict):\n",
    "    \n",
    "    all_uniques = get_all_uniques(vocabs_dict.values())\n",
    "    unique_dict = {}\n",
    "    \n",
    "    for tag, vocab in vocabs_dict.items():\n",
    "        unique_dict[tag] = []\n",
    "        for w in vocab:\n",
    "            if w in all_uniques:\n",
    "                unique_dict[tag].append(w)\n",
    "    \n",
    "    return unique_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict(vocab, tag):\n",
    "    d = {}\n",
    "    for w in vocab:\n",
    "        d[w] = tag\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(dicts): \n",
    "    super_dict = {}\n",
    "    for d in dicts:\n",
    "        for k, v in d.items():\n",
    "            super_dict[k] = v\n",
    "    return super_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_common(l1,l2):\n",
    "    result = False\n",
    "    for x in l1: \n",
    "        for y in l2: \n",
    "            if x == y:\n",
    "                print(\"Got same:\", x, y)\n",
    "                result = True\n",
    "                return result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another pathetic Word2Vec attempt.\n",
    "Fuck me up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(l):\n",
    "    lmin = min(l)\n",
    "    lmax = max(l)\n",
    "    return [(v-lmin)/(lmax-lmin) for v in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(d, rev):\n",
    "    return sorted(d.items(), key=lambda kv: kv[1], reverse=rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec_docs(df):\n",
    "    verses = list(df[\"VerseText\"])\n",
    "    docs = [clean_text(v) for v in verses]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_origin(model, origin_word):\n",
    "    \n",
    "    # gets the original vector for the chosen origin word\n",
    "    origin_vec = model.wv.get_vector(origin_word)\n",
    "    \n",
    "    # used to calculate the new origin\n",
    "    zero_vec = np.zeros(origin_vec.shape)\n",
    "    \n",
    "    # vector to shift each point by everything by\n",
    "    transformation_vec = zero_vec - origin_vec\n",
    "    \n",
    "    # dict to store all the new vectors\n",
    "    transformed_vecs = {}\n",
    "    \n",
    "    for w in model.wv.vocab:\n",
    "        # original vector for the word\n",
    "        w_vec = model.wv.get_vector(w)\n",
    "        \n",
    "        # shifted by the transformation\n",
    "        transformed_w_vec = w_vec + transformation_vec\n",
    "        \n",
    "        # store\n",
    "        transformed_vecs[w] = transformed_w_vec\n",
    "        \n",
    "    return transformed_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the documents from each text.\n",
    "ot_docs = get_word2vec_docs(ot_df)\n",
    "nt_docs = get_word2vec_docs(nt_df)\n",
    "q_docs = get_word2vec_docs(q_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global hyper parameters\n",
    "hp = {\n",
    "    \"size\": 150, # size of the one-hot-encoded word vectors\n",
    "    \"window\": 20, # context size\n",
    "    \"min_count\": 2,\n",
    "    \"workers\": 4,\n",
    "    \"iter\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(docs):\n",
    "    model = gensim.models.Word2Vec(\n",
    "        docs,\n",
    "        size=hp[\"size\"],\n",
    "        window=hp[\"window\"],\n",
    "        min_count=hp[\"min_count\"],\n",
    "        workers=hp[\"workers\"])\n",
    "\n",
    "    model.train(docs, total_examples=len(docs), epochs=50)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train the models on each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : PROGRESS: at sentence #10000, processed 97904 words, keeping 5861 word types\n",
      "INFO : PROGRESS: at sentence #20000, processed 182562 words, keeping 8873 word types\n",
      "INFO : collected 9377 word types from a corpus of 214613 raw words and 23145 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : min_count=2 retains 6304 unique words (67% of original 9377, drops 3073)\n",
      "INFO : min_count=2 leaves 211540 word corpus (98% of original 214613, drops 3073)\n",
      "INFO : deleting the raw counts dictionary of 9377 items\n",
      "INFO : sample=0.001 downsamples 44 most-common words\n",
      "INFO : downsampling leaves estimated 184285 word corpus (87.1% of prior 211540)\n",
      "INFO : estimated required memory for 6304 words and 150 dimensions: 10716800 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : training model with 4 workers on 6304 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 214613 raw words (184380 effective words) took 0.2s, 914993 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 214613 raw words (184336 effective words) took 0.2s, 943745 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 214613 raw words (184225 effective words) took 0.2s, 919267 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 214613 raw words (184384 effective words) took 0.2s, 878205 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 214613 raw words (184259 effective words) took 0.2s, 859189 effective words/s\n",
      "INFO : training on a 1073065 raw words (921584 effective words) took 1.1s, 847902 effective words/s\n",
      "WARNING : Effective 'alpha' higher than previous training cycles\n",
      "INFO : training model with 4 workers on 6304 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 214613 raw words (184378 effective words) took 0.2s, 940392 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 214613 raw words (184366 effective words) took 0.2s, 945934 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 214613 raw words (184268 effective words) took 0.2s, 956870 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 214613 raw words (184380 effective words) took 0.2s, 937036 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 214613 raw words (184180 effective words) took 0.2s, 918783 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 6 : training on 214613 raw words (184301 effective words) took 0.2s, 880454 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 7 : training on 214613 raw words (184241 effective words) took 0.2s, 943805 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 8 : training on 214613 raw words (184577 effective words) took 0.2s, 919324 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 9 : training on 214613 raw words (184231 effective words) took 0.2s, 876947 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 10 : training on 214613 raw words (184271 effective words) took 0.2s, 814053 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 11 : training on 214613 raw words (184183 effective words) took 0.2s, 842049 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 12 : training on 214613 raw words (184359 effective words) took 0.2s, 834410 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 13 : training on 214613 raw words (184179 effective words) took 0.2s, 897794 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 14 : training on 214613 raw words (184236 effective words) took 0.2s, 876683 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 15 : training on 214613 raw words (184123 effective words) took 0.2s, 920216 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 16 : training on 214613 raw words (184254 effective words) took 0.2s, 939389 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 17 : training on 214613 raw words (184262 effective words) took 0.2s, 943999 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 18 : training on 214613 raw words (184227 effective words) took 0.2s, 906361 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 19 : training on 214613 raw words (184185 effective words) took 0.2s, 950315 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 20 : training on 214613 raw words (184250 effective words) took 0.2s, 962724 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 21 : training on 214613 raw words (184524 effective words) took 0.2s, 954898 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 22 : training on 214613 raw words (184422 effective words) took 0.2s, 929463 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 23 : training on 214613 raw words (184449 effective words) took 0.2s, 946306 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 24 : training on 214613 raw words (184292 effective words) took 0.2s, 939760 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 25 : training on 214613 raw words (184043 effective words) took 0.2s, 944112 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 26 : training on 214613 raw words (184120 effective words) took 0.2s, 954404 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 27 : training on 214613 raw words (184186 effective words) took 0.2s, 984342 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 28 : training on 214613 raw words (184231 effective words) took 0.2s, 901101 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 29 : training on 214613 raw words (184227 effective words) took 0.2s, 924178 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 30 : training on 214613 raw words (184293 effective words) took 0.2s, 907457 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 31 : training on 214613 raw words (184472 effective words) took 0.2s, 963454 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 32 : training on 214613 raw words (184220 effective words) took 0.2s, 957098 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 33 : training on 214613 raw words (184225 effective words) took 0.2s, 930564 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 34 : training on 214613 raw words (184184 effective words) took 0.2s, 905227 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 35 : training on 214613 raw words (184254 effective words) took 0.2s, 960048 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : EPOCH - 36 : training on 214613 raw words (184209 effective words) took 0.2s, 888826 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 37 : training on 214613 raw words (184264 effective words) took 0.2s, 951444 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 38 : training on 214613 raw words (184217 effective words) took 0.2s, 932075 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 39 : training on 214613 raw words (184207 effective words) took 0.2s, 975062 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 40 : training on 214613 raw words (184313 effective words) took 0.2s, 947712 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 41 : training on 214613 raw words (184185 effective words) took 0.2s, 945373 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 42 : training on 214613 raw words (184168 effective words) took 0.2s, 957367 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 43 : training on 214613 raw words (184177 effective words) took 0.2s, 899655 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 44 : training on 214613 raw words (184157 effective words) took 0.2s, 817825 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 45 : training on 214613 raw words (184270 effective words) took 0.2s, 787458 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 46 : training on 214613 raw words (184289 effective words) took 0.2s, 841368 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 47 : training on 214613 raw words (184471 effective words) took 0.2s, 780267 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 48 : training on 214613 raw words (184494 effective words) took 0.2s, 864670 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 49 : training on 214613 raw words (184066 effective words) took 0.2s, 932218 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 50 : training on 214613 raw words (184386 effective words) took 0.2s, 896670 effective words/s\n",
      "INFO : training on a 10730650 raw words (9213466 effective words) took 10.8s, 853483 effective words/s\n"
     ]
    }
   ],
   "source": [
    "ot_model = get_model(ot_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : collected 5152 word types from a corpus of 60551 raw words and 7957 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : min_count=2 retains 3417 unique words (66% of original 5152, drops 1735)\n",
      "INFO : min_count=2 leaves 58816 word corpus (97% of original 60551, drops 1735)\n",
      "INFO : deleting the raw counts dictionary of 5152 items\n",
      "INFO : sample=0.001 downsamples 59 most-common words\n",
      "INFO : downsampling leaves estimated 52063 word corpus (88.5% of prior 58816)\n",
      "INFO : estimated required memory for 3417 words and 150 dimensions: 5808900 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : training model with 4 workers on 3417 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 60551 raw words (52038 effective words) took 0.1s, 708880 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 60551 raw words (52071 effective words) took 0.1s, 648662 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 60551 raw words (52034 effective words) took 0.1s, 725003 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 60551 raw words (52093 effective words) took 0.1s, 732818 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 60551 raw words (52043 effective words) took 0.1s, 653494 effective words/s\n",
      "INFO : training on a 302755 raw words (260279 effective words) took 0.4s, 584729 effective words/s\n",
      "WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "WARNING : Effective 'alpha' higher than previous training cycles\n",
      "INFO : training model with 4 workers on 3417 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 60551 raw words (51959 effective words) took 0.1s, 769830 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 60551 raw words (52102 effective words) took 0.1s, 747289 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 60551 raw words (52137 effective words) took 0.1s, 709620 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 60551 raw words (52100 effective words) took 0.1s, 695888 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 60551 raw words (51963 effective words) took 0.1s, 683158 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 6 : training on 60551 raw words (52015 effective words) took 0.1s, 667263 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 7 : training on 60551 raw words (52079 effective words) took 0.1s, 746907 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 8 : training on 60551 raw words (52124 effective words) took 0.1s, 710916 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 9 : training on 60551 raw words (52028 effective words) took 0.1s, 662689 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 10 : training on 60551 raw words (52193 effective words) took 0.1s, 701927 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 11 : training on 60551 raw words (52084 effective words) took 0.1s, 668823 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 12 : training on 60551 raw words (52094 effective words) took 0.1s, 803725 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 13 : training on 60551 raw words (52007 effective words) took 0.1s, 655908 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 14 : training on 60551 raw words (52188 effective words) took 0.1s, 687698 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 15 : training on 60551 raw words (52053 effective words) took 0.1s, 622021 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 16 : training on 60551 raw words (51905 effective words) took 0.1s, 693458 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 17 : training on 60551 raw words (52094 effective words) took 0.1s, 583407 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 18 : training on 60551 raw words (52113 effective words) took 0.1s, 773946 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 19 : training on 60551 raw words (52035 effective words) took 0.1s, 712587 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 20 : training on 60551 raw words (52016 effective words) took 0.1s, 739032 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 21 : training on 60551 raw words (52125 effective words) took 0.1s, 772408 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 22 : training on 60551 raw words (52067 effective words) took 0.1s, 652596 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 23 : training on 60551 raw words (52035 effective words) took 0.1s, 764272 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 24 : training on 60551 raw words (52111 effective words) took 0.1s, 766323 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 25 : training on 60551 raw words (52157 effective words) took 0.1s, 777529 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 26 : training on 60551 raw words (52020 effective words) took 0.1s, 659627 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 27 : training on 60551 raw words (52092 effective words) took 0.1s, 732082 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 28 : training on 60551 raw words (52052 effective words) took 0.1s, 735625 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 29 : training on 60551 raw words (52108 effective words) took 0.1s, 718391 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 30 : training on 60551 raw words (52183 effective words) took 0.1s, 804948 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 31 : training on 60551 raw words (52088 effective words) took 0.1s, 800113 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 32 : training on 60551 raw words (52016 effective words) took 0.1s, 769827 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 33 : training on 60551 raw words (52160 effective words) took 0.1s, 750508 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 34 : training on 60551 raw words (52179 effective words) took 0.1s, 757107 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 35 : training on 60551 raw words (52182 effective words) took 0.1s, 708222 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 36 : training on 60551 raw words (52030 effective words) took 0.1s, 740212 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 37 : training on 60551 raw words (52013 effective words) took 0.1s, 714138 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 38 : training on 60551 raw words (52089 effective words) took 0.1s, 829113 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 39 : training on 60551 raw words (52099 effective words) took 0.1s, 1025131 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 40 : training on 60551 raw words (52135 effective words) took 0.1s, 788936 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 41 : training on 60551 raw words (52024 effective words) took 0.1s, 828465 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 42 : training on 60551 raw words (52115 effective words) took 0.1s, 654716 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 43 : training on 60551 raw words (52009 effective words) took 0.1s, 744716 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 44 : training on 60551 raw words (52045 effective words) took 0.1s, 701462 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 45 : training on 60551 raw words (52022 effective words) took 0.1s, 797575 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 46 : training on 60551 raw words (52046 effective words) took 0.1s, 759227 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 47 : training on 60551 raw words (52072 effective words) took 0.1s, 811164 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 48 : training on 60551 raw words (52082 effective words) took 0.1s, 766593 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 49 : training on 60551 raw words (52101 effective words) took 0.1s, 783640 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 50 : training on 60551 raw words (52055 effective words) took 0.1s, 758839 effective words/s\n",
      "INFO : training on a 3027550 raw words (2603801 effective words) took 4.3s, 607343 effective words/s\n"
     ]
    }
   ],
   "source": [
    "nt_model = get_model(nt_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : collected 5703 word types from a corpus of 56975 raw words and 6236 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : min_count=2 retains 3466 unique words (60% of original 5703, drops 2237)\n",
      "INFO : min_count=2 leaves 54738 word corpus (96% of original 56975, drops 2237)\n",
      "INFO : deleting the raw counts dictionary of 5703 items\n",
      "INFO : sample=0.001 downsamples 45 most-common words\n",
      "INFO : downsampling leaves estimated 48112 word corpus (87.9% of prior 54738)\n",
      "INFO : estimated required memory for 3466 words and 150 dimensions: 5892200 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : training model with 4 workers on 3466 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 56975 raw words (48162 effective words) took 0.1s, 619416 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 56975 raw words (48073 effective words) took 0.1s, 623261 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 56975 raw words (48084 effective words) took 0.1s, 665521 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 56975 raw words (48078 effective words) took 0.1s, 729950 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 56975 raw words (48101 effective words) took 0.1s, 767093 effective words/s\n",
      "INFO : training on a 284875 raw words (240498 effective words) took 0.4s, 562993 effective words/s\n",
      "WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "WARNING : Effective 'alpha' higher than previous training cycles\n",
      "INFO : training model with 4 workers on 3466 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 56975 raw words (48053 effective words) took 0.1s, 641426 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 56975 raw words (48114 effective words) took 0.1s, 749141 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 56975 raw words (48105 effective words) took 0.1s, 715758 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 56975 raw words (48084 effective words) took 0.1s, 678443 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 56975 raw words (48129 effective words) took 0.1s, 724191 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 6 : training on 56975 raw words (48142 effective words) took 0.1s, 695876 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 7 : training on 56975 raw words (48136 effective words) took 0.1s, 674452 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 8 : training on 56975 raw words (48142 effective words) took 0.1s, 697219 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 9 : training on 56975 raw words (48103 effective words) took 0.1s, 819759 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 10 : training on 56975 raw words (48143 effective words) took 0.1s, 735019 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 11 : training on 56975 raw words (48053 effective words) took 0.1s, 717959 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 12 : training on 56975 raw words (48031 effective words) took 0.1s, 732382 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 13 : training on 56975 raw words (48108 effective words) took 0.1s, 690092 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 14 : training on 56975 raw words (48158 effective words) took 0.1s, 764690 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 15 : training on 56975 raw words (48245 effective words) took 0.1s, 786063 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 16 : training on 56975 raw words (48116 effective words) took 0.1s, 774424 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 17 : training on 56975 raw words (48103 effective words) took 0.1s, 803581 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 18 : training on 56975 raw words (48044 effective words) took 0.1s, 732439 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 19 : training on 56975 raw words (48113 effective words) took 0.1s, 747919 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 20 : training on 56975 raw words (48189 effective words) took 0.1s, 757605 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 21 : training on 56975 raw words (48059 effective words) took 0.1s, 788977 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 22 : training on 56975 raw words (48152 effective words) took 0.1s, 698167 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 23 : training on 56975 raw words (48095 effective words) took 0.1s, 753386 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 24 : training on 56975 raw words (48063 effective words) took 0.1s, 760028 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 25 : training on 56975 raw words (48103 effective words) took 0.1s, 731093 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 26 : training on 56975 raw words (48105 effective words) took 0.1s, 769967 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 27 : training on 56975 raw words (48092 effective words) took 0.1s, 784886 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 28 : training on 56975 raw words (48035 effective words) took 0.1s, 818703 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 29 : training on 56975 raw words (48118 effective words) took 0.1s, 778030 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 30 : training on 56975 raw words (48115 effective words) took 0.1s, 764814 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 31 : training on 56975 raw words (48117 effective words) took 0.1s, 756877 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 32 : training on 56975 raw words (48073 effective words) took 0.1s, 787327 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 33 : training on 56975 raw words (48148 effective words) took 0.1s, 695007 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 34 : training on 56975 raw words (48156 effective words) took 0.1s, 752303 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 35 : training on 56975 raw words (48172 effective words) took 0.1s, 780810 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 36 : training on 56975 raw words (48186 effective words) took 0.1s, 775962 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 37 : training on 56975 raw words (48217 effective words) took 0.1s, 766064 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 38 : training on 56975 raw words (48220 effective words) took 0.1s, 814816 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 39 : training on 56975 raw words (48203 effective words) took 0.1s, 741423 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 40 : training on 56975 raw words (48026 effective words) took 0.1s, 750788 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 41 : training on 56975 raw words (47984 effective words) took 0.1s, 837805 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 42 : training on 56975 raw words (48194 effective words) took 0.1s, 797393 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 43 : training on 56975 raw words (48094 effective words) took 0.1s, 784371 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 44 : training on 56975 raw words (48100 effective words) took 0.1s, 790528 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 45 : training on 56975 raw words (48116 effective words) took 0.1s, 812899 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 46 : training on 56975 raw words (48066 effective words) took 0.1s, 750704 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 47 : training on 56975 raw words (48001 effective words) took 0.1s, 793648 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 48 : training on 56975 raw words (48183 effective words) took 0.1s, 799843 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 49 : training on 56975 raw words (48112 effective words) took 0.1s, 765474 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 50 : training on 56975 raw words (48125 effective words) took 0.1s, 745750 effective words/s\n",
      "INFO : training on a 2848750 raw words (2405741 effective words) took 3.9s, 622468 effective words/s\n"
     ]
    }
   ],
   "source": [
    "q_model = get_model(q_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "ot_X = ot_model[ot_model.wv.vocab]\n",
    "ot_reduced = pca.fit_transform(ot_X)\n",
    "\n",
    "nt_X = nt_model[nt_model.wv.vocab]\n",
    "nt_reduced = pca.fit_transform(nt_X)\n",
    "\n",
    "q_X = q_model[q_model.wv.vocab]\n",
    "q_reduced = pca.fit_transform(q_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_dict = {}\n",
    "wv_dict[\"ot\"] = {}\n",
    "wv_dict[\"nt\"] = {}\n",
    "wv_dict[\"q\"] = {}\n",
    "\n",
    "for i, word in enumerate(list(ot_model.wv.vocab)):\n",
    "    wv_dict[\"ot\"][word] = [float(ot_reduced[i][0]),float(ot_reduced[i][1])]\n",
    "    \n",
    "for i, word in enumerate(list(nt_model.wv.vocab)):\n",
    "    wv_dict[\"nt\"][word] = [float(nt_reduced[i][0]),float(nt_reduced[i][1])]\n",
    "    \n",
    "for i, word in enumerate(list(q_model.wv.vocab)):\n",
    "    wv_dict[\"q\"][word] = [float(q_reduced[i][0]),float(q_reduced[i][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygon construction from Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import geometry as g\n",
    "from dxfwrite import DXFEngine as dxf\n",
    "from dxfwrite.const import CENTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['god', 'heaven', 'hell', 'love', 'hate', 'free', 'light', 'darkness', 'peace', 'war', 'life', 'death', 'man', 'woman', 'child', 'eat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n"
     ]
    }
   ],
   "source": [
    "topic_vecs = {}\n",
    "\n",
    "for t in topics:\n",
    "    topic_vecs[t] = {}\n",
    "\n",
    "    # go through each religion\n",
    "    for rel in wv_dict:\n",
    "        \n",
    "        model = None\n",
    "        if rel == 'ot':\n",
    "            model = ot_model\n",
    "        elif rel == 'nt':\n",
    "            model = nt_model\n",
    "        elif rel == 'q':\n",
    "            model = q_model\n",
    "            \n",
    "        most_sim = model.most_similar(positive=[t], topn=5)\n",
    "        topic_vecs[t][rel] = {\n",
    "            \"vec\": wv_dict[rel][t],\n",
    "            \"sim\": {}\n",
    "        }\n",
    "        \n",
    "#         print(wv_dict)\n",
    "        for w in most_sim:\n",
    "            wv = wv_dict[rel][w[0]]\n",
    "            topic_vecs[t][rel][\"sim\"][w[0]] = wv_dict[rel][w[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'god': {'ot': {'vec': [-2.27060866355896, -3.132342576980591],\n",
       "   'sim': {'lord': [-2.1962146759033203, -2.4795944690704346],\n",
       "    'worship': [-1.1756192445755005, -1.30728280544281],\n",
       "    'worshipped': [1.4347145557403564, -2.2107770442962646],\n",
       "    'jealous': [-1.7164735794067383, -2.051520824432373],\n",
       "    'sworn': [-2.2373297214508057, -3.513554573059082]}},\n",
       "  'nt': {'vec': [-2.013201951980591, -0.5630126595497131],\n",
       "   'sim': {'amen': [-2.368495225906372, -0.653245210647583],\n",
       "    'saviour': [-2.4734528064727783, -1.298343539237976],\n",
       "    'sceptre': [-0.3421207666397095, 0.306600421667099],\n",
       "    'salvation': [-3.8624179363250732, -2.0293500423431396],\n",
       "    'fellowship': [-1.4601202011108398, -1.3096134662628174]}},\n",
       "  'q': {'vec': [-1.507064700126648, -3.598748207092285],\n",
       "   'sim': {'worship': [4.105205059051514, -2.5894370079040527],\n",
       "    'centre': [-0.022862084209918976, -1.2361050844192505],\n",
       "    'fashion': [-0.3592420220375061, -0.3114739954471588],\n",
       "    'idol': [-0.19077439606189728, 0.6185432076454163],\n",
       "    'passion': [-0.041346754878759384, -0.3988719880580902]}}},\n",
       " 'heaven': {'ot': {'vec': [-3.7842860221862793, 0.7659249305725098],\n",
       "   'sim': {'fowl': [-1.6826330423355103, 4.093809604644775],\n",
       "    'air': [-1.9242802858352661, 1.2885605096817017],\n",
       "    'dew': [-2.4361307621002197, 4.197526454925537],\n",
       "    'herewith': [-0.737745463848114, -0.35795196890830994],\n",
       "    'lap': [-0.540870726108551, 0.6926699876785278]}},\n",
       "  'nt': {'vec': [1.8676573038101196, 3.744457244873047],\n",
       "   'sim': {'passion': [-0.12971378862857819, 0.061544764786958694],\n",
       "    'earthquake': [3.6864771842956543, 2.5344910621643066],\n",
       "    'lightning': [1.863402009010315, 2.1706457138061523],\n",
       "    'thunderings': [1.083380103111267, 1.211559772491455],\n",
       "    'sware': [-0.5873686671257019, 0.8471788167953491]}},\n",
       "  'q': {'vec': [-3.030538320541382, -1.4271814823150635],\n",
       "   'sim': {'established': [-1.4870524406433105, -1.882193922996521],\n",
       "    'proportion': [-2.3455705642700195, 1.7544293403625488],\n",
       "    'belongeth': [-0.7382834553718567, -0.06795545667409897],\n",
       "    'creator': [-0.8660788536071777, 0.02208763174712658],\n",
       "    'creature': [-1.543744444847107, 2.245936393737793]}}},\n",
       " 'hell': {'ot': {'vec': [-3.9655239582061768, 3.5709354877471924],\n",
       "   'sim': {'scourge': [-1.8743410110473633, 0.9498924612998962],\n",
       "    'overflowing': [-2.1894869804382324, 3.813063144683838],\n",
       "    'lowest': [-1.184545874595642, 0.8026770949363708],\n",
       "    'heapeth': [-1.1366658210754395, -0.23248344659805298],\n",
       "    'tossed': [-1.2274843454360962, 0.3361590504646301]}},\n",
       "  'nt': {'vec': [1.0747169256210327, 3.7627298831939697],\n",
       "   'sim': {'quenched': [-0.06658263504505157, 1.863004446029663],\n",
       "    'offend': [-1.5873037576675415, 5.515108585357666],\n",
       "    'raiment': [1.7128299474716187, 4.586393356323242],\n",
       "    'hanged': [0.23563958704471588, 1.5242090225219727],\n",
       "    'pluck': [-0.4049130976200104, 1.368493914604187]}},\n",
       "  'q': {'vec': [-0.19067291915416718, 0.4218658208847046],\n",
       "   'sim': {'abode': [-0.3617000877857208, -0.5289968252182007],\n",
       "    'an': [-0.021063726395368576, -0.180894136428833],\n",
       "    'destination': [0.7550533413887024, -0.2091490626335144],\n",
       "    'burn': [0.1952756643295288, 0.0715656578540802],\n",
       "    'misery': [-0.6166741251945496, -0.35634931921958923]}}},\n",
       " 'love': {'ot': {'vec': [-2.2598459720611572, -0.8469902873039246],\n",
       "   'sim': {'guide': [-1.268342137336731, 0.05921586602926254],\n",
       "    'alienated': [-0.2352946400642395, -0.6081637740135193],\n",
       "    'simplicity': [-0.4142339825630188, -0.3646688461303711],\n",
       "    'hateth': [-1.7763943672180176, -0.6260093450546265],\n",
       "    'forsaketh': [-1.286539912223816, -0.8579127192497253]}},\n",
       "  'nt': {'vec': [-4.02672815322876, -0.3354974687099457],\n",
       "   'sim': {'bowel': [-1.6098238229751587, -0.21854735910892487],\n",
       "    'brotherly': [-1.4608534574508667, -0.580693244934082],\n",
       "    'unfeigned': [-0.7967758774757385, -0.4761662185192108],\n",
       "    'commendeth': [-1.037711501121521, -0.3216504752635956],\n",
       "    'kindness': [-2.072831630706787, -0.5041359663009644]}},\n",
       "  'q': {'vec': [4.28062105178833, 3.6793885231018066],\n",
       "   'sim': {'hatred': [2.157352924346924, -0.4881633222103119],\n",
       "    'anchorite': [0.31208157539367676, 0.04255550354719162],\n",
       "    'priest': [0.26796773076057434, -0.0018938190769404173],\n",
       "    'manifold': [0.3691830635070801, 1.442442536354065],\n",
       "    'substance': [0.8511655926704407, 4.789947032928467]}}},\n",
       " 'hate': {'ot': {'vec': [-3.181401491165161, -2.422961950302124],\n",
       "   'sim': {'liftest': [-0.32821086049079895, -0.046338677406311035],\n",
       "    'rewarded': [-1.0193843841552734, -1.2597793340682983],\n",
       "    'preserveth': [-0.8831785321235657, -0.3776156008243561],\n",
       "    'puffeth': [-0.9344927668571472, -0.36013326048851013],\n",
       "    'hardeneth': [-0.6164487600326538, -0.0967172160744667]}},\n",
       "  'nt': {'vec': [-2.3199455738067627, 0.508705735206604],\n",
       "   'sim': {'mammon': [-1.5447797775268555, 0.19079704582691193],\n",
       "    'nicolaitans': [-0.6179605722427368, -0.06331201642751694],\n",
       "    'enemy': [-0.9468818306922913, 1.7876555919647217],\n",
       "    'despitefully': [-0.8332458138465881, -0.13224190473556519],\n",
       "    'unthankful': [-1.2698192596435547, 0.17709988355636597]}},\n",
       "  'q': {'vec': [0.8388147950172424, -1.333115816116333],\n",
       "   'sim': {'assert': [0.5091338157653809, -1.4908466339111328],\n",
       "    'christian': [3.719179630279541, -2.829934597015381],\n",
       "    'did': [0.5112489461898804, -1.0138236284255981],\n",
       "    'upon': [0.49794599413871765, -0.5566674470901489],\n",
       "    'doctrine': [0.3149321675300598, -0.5602385997772217]}}},\n",
       " 'free': {'ot': {'vec': [0.7159512042999268, -2.8215579986572266],\n",
       "   'sim': {'maidservant': [1.6356492042541504, -1.0098514556884766],\n",
       "    'manservant': [1.9321638345718384, -0.9301469922065735],\n",
       "    'wage': [-0.6943798065185547, 0.9351912140846252],\n",
       "    'serving': [-0.2980971038341522, -1.0795931816101074],\n",
       "    'betrothed': [0.21439489722251892, -0.7993779182434082]}},\n",
       "  'nt': {'vec': [-1.991292953491211, -1.8899856805801392],\n",
       "   'sim': {'justification': [-1.192483901977539, -0.4997657537460327],\n",
       "    'duty': [-0.856789767742157, -0.18880534172058105],\n",
       "    'liberty': [-2.5751430988311768, -1.1898001432418823],\n",
       "    'debt': [-0.6740487813949585, -0.24262839555740356],\n",
       "    'deacon': [-0.7339853048324585, -0.4981085956096649]}},\n",
       "  'q': {'vec': [1.1872813701629639, 6.705020427703857],\n",
       "   'sim': {'want': [0.38425472378730774, 5.136519908905029],\n",
       "    'slave': [3.3236255645751953, 6.699827671051025],\n",
       "    'manner': [1.1441524028778076, 2.4942054748535156],\n",
       "    '´iddat': [0.7717276811599731, 2.1431899070739746],\n",
       "    'handsome': [-0.24359628558158875, 1.5139416456222534]}}},\n",
       " 'light': {'ot': {'vec': [-2.7336196899414062, -0.659562349319458],\n",
       "   'sim': {'darkness': [-5.263697624206543, 1.4787403345108032],\n",
       "    'obscurity': [-0.7170765399932861, -0.3100275993347168],\n",
       "    'noonday': [-2.6771678924560547, 0.831888735294342],\n",
       "    'shining': [-0.5957829356193542, 1.5349534749984741],\n",
       "    'shineth': [-0.17370818555355072, 0.2543419301509857]}},\n",
       "  'nt': {'vec': [-0.477784126996994, 4.416034698486328],\n",
       "   'sim': {'shine': [-0.3427196741104126, 1.488842487335205],\n",
       "    'darkness': [-0.2489367127418518, 4.145729064941406],\n",
       "    'candle': [0.8234414458274841, 2.9042601585388184],\n",
       "    'bushel': [0.2805826961994171, 0.9975988268852234],\n",
       "    'lighten': [-0.056505877524614334, 0.27278760075569153]}},\n",
       "  'q': {'vec': [-1.580208420753479, 1.0977873802185059],\n",
       "   'sim': {'darkness': [-5.590396404266357, -1.581593632698059],\n",
       "    'depth': [-3.626162528991699, -1.8737757205963135],\n",
       "    'lit': [-1.7180163860321045, 0.4069371819496155],\n",
       "    'lamp': [-3.684037685394287, -0.28533676266670227],\n",
       "    'containing': [-0.12414558231830597, -0.5639300346374512]}}},\n",
       " 'darkness': {'ot': {'vec': [-5.263697624206543, 1.4787403345108032],\n",
       "   'sim': {'obscurity': [-0.7170765399932861, -0.3100275993347168],\n",
       "    'light': [-2.7336196899414062, -0.659562349319458],\n",
       "    'shadow': [-4.381687164306641, 4.739102363586426],\n",
       "    'noonday': [-2.6771678924560547, 0.831888735294342],\n",
       "    'cloud': [-3.220139741897583, 3.4801442623138428]}},\n",
       "  'nt': {'vec': [-0.2489367127418518, 4.145729064941406],\n",
       "   'sim': {'light': [-0.477784126996994, 4.416034698486328],\n",
       "    'shine': [-0.3427196741104126, 1.488842487335205],\n",
       "    'mist': [0.5229915380477905, 0.9645929336547852],\n",
       "    'bushel': [0.2805826961994171, 0.9975988268852234],\n",
       "    'blackness': [0.8628066182136536, 0.9262501001358032]}},\n",
       "  'q': {'vec': [-5.590396404266357, -1.581593632698059],\n",
       "   'sim': {'depth': [-3.626162528991699, -1.8737757205963135],\n",
       "    'light': [-1.580208420753479, 1.0977873802185059],\n",
       "    'lamp': [-3.684037685394287, -0.28533676266670227],\n",
       "    'billow': [-2.0249500274658203, -0.5266172289848328],\n",
       "    'topped': [-1.9946104288101196, -0.5174912214279175]}}},\n",
       " 'peace': {'ot': {'vec': [-0.9078693985939026, -2.1724674701690674],\n",
       "   'sim': {'imputed': [-0.7766162157058716, -0.4055020213127136],\n",
       "    'sacrifice': [-2.1787302494049072, -2.0909528732299805],\n",
       "    'freewill': [-0.12145049124956131, -1.5463870763778687],\n",
       "    'pertain': [-0.9847360849380493, -0.08109083771705627],\n",
       "    'heave': [1.6640437841415405, -0.6979129314422607]}},\n",
       "  'nt': {'vec': [-0.27865108847618103, -1.5264217853546143],\n",
       "   'sim': {'adjure': [-0.2267804890871048, -0.877411425113678],\n",
       "    'direct': [-0.39856091141700745, -0.4794568419456482],\n",
       "    'unity': [-0.5801124572753906, -0.25727578997612],\n",
       "    'held': [1.6710504293441772, -2.3582746982574463],\n",
       "    'preserved': [-0.6396015882492065, -0.5876080989837646]}},\n",
       "  'q': {'vec': [2.1180710792541504, 0.8888424634933472],\n",
       "   'sim': {'salutation': [0.2222602814435959, 0.3599599301815033],\n",
       "    'guarantee': [0.16162973642349243, 0.1341322511434555],\n",
       "    'withdraw': [-0.12065671384334564, 0.1527673602104187],\n",
       "    'rewarded': [0.39812201261520386, 0.8827292919158936],\n",
       "    'exile': [3.0715413093566895, 1.189982295036316]}}},\n",
       " 'war': {'ot': {'vec': [0.687616765499115, -1.9556857347488403],\n",
       "   'sim': {'battle': [-0.5053219795227051, -1.8420501947402954],\n",
       "    'band': [0.1837284415960312, 0.9175645709037781],\n",
       "    'valour': [5.165658473968506, -1.2491551637649536],\n",
       "    'fighting': [-0.16545911133289337, -0.31720760464668274],\n",
       "    'fight': [-1.1443108320236206, -1.740078330039978]}},\n",
       "  'nt': {'vec': [-1.37395179271698, 2.26507568359375],\n",
       "   'sim': {'rumour': [0.1487780660390854, -0.18098846077919006],\n",
       "    'fold': [0.0924752950668335, 0.0936468318104744],\n",
       "    'incorruption': [-0.7012200951576233, 1.0026878118515015],\n",
       "    'soweth': [-1.6553293466567993, 2.517190933227539],\n",
       "    'incorruptible': [-0.7917677760124207, 1.2120949029922485]}},\n",
       "  'q': {'vec': [3.0149569511413574, 4.075877666473389],\n",
       "   'sim': {'thoroughly': [0.3842262625694275, 0.25750190019607544],\n",
       "    'subdued': [0.6971643567085266, 0.19518384337425232],\n",
       "    'captive': [1.9546210765838623, 1.4886577129364014],\n",
       "    'lagged': [1.159303069114685, 0.5761200189590454],\n",
       "    'vehement': [0.6248311400413513, -0.12416496872901917]}}},\n",
       " 'life': {'ot': {'vec': [-2.6904945373535156, -3.0731966495513916],\n",
       "   'sim': {'seek': [-4.749518871307373, -2.5058300495147705],\n",
       "    'handmaid': [-1.2591824531555176, -3.9726691246032715],\n",
       "    'eatest': [-0.2743176817893982, -0.46629536151885986],\n",
       "    'juniper': [-0.5019125938415527, 0.6249560713768005],\n",
       "    'sought': [-0.09485944360494614, -4.5694050788879395]}},\n",
       "  'nt': {'vec': [-3.0185399055480957, 2.3469550609588623],\n",
       "   'sim': {'everlasting': [-2.9885411262512207, 1.5762327909469604],\n",
       "    'eternal': [-3.5447001457214355, 0.30996742844581604],\n",
       "    'reapeth': [-1.3722552061080933, 0.6206952333450317],\n",
       "    'endureth': [-1.5301082134246826, 0.9578183889389038],\n",
       "    'callest': [-0.5763024091720581, 0.007989262230694294]}},\n",
       "  'q': {'vec': [0.26812463998794556, 1.4759583473205566],\n",
       "   'sim': {'amusement': [-0.37112370133399963, 0.8580337166786194],\n",
       "    'world': [-0.36038628220558167, 0.2737449109554291],\n",
       "    'present': [0.059209808707237244, 0.7190890312194824],\n",
       "    'play': [-0.21447154879570007, -0.17940539121627808],\n",
       "    'convenience': [-0.6849856972694397, 1.6730540990829468]}}},\n",
       " 'death': {'ot': {'vec': [-1.987944483757019, -2.2554948329925537],\n",
       "   'sim': {'die': [-3.7830810546875, -3.557847499847412],\n",
       "    'hid': [-1.8991246223449707, 0.07213082909584045],\n",
       "    'worthy': [-0.7980988621711731, -1.0156100988388062],\n",
       "    'leper': [0.8203345537185669, 1.0440493822097778],\n",
       "    'killeth': [-0.9728025197982788, -0.7959017157554626]}},\n",
       "  'nt': {'vec': [-1.0900750160217285, -0.020963318645954132],\n",
       "   'sim': {'taste': [0.11055437475442886, -0.3218841254711151],\n",
       "    'point': [-0.19270630180835724, -0.3184584081172943],\n",
       "    'testator': [-0.4023831784725189, 0.20507967472076416],\n",
       "    'translated': [-0.477640300989151, -0.2420714795589447],\n",
       "    'immortality': [-0.7590444684028625, 0.5559276342391968]}},\n",
       "  'q': {'vec': [-1.1856715679168701, -1.4698938131332397],\n",
       "   'sim': {'bequest': [0.4046194553375244, 0.8504524827003479],\n",
       "    'purge': [0.019311293959617615, -0.34705111384391785],\n",
       "    'die': [-2.114534616470337, 1.7829660177230835],\n",
       "    'decreed': [-0.9514275789260864, 0.02371969074010849],\n",
       "    'reply': [-0.051882024854421616, -2.3708930015563965]}}},\n",
       " 'man': {'ot': {'vec': [-1.7397876977920532, -1.658074140548706],\n",
       "   'sim': {'men': [-0.37602704763412476, -1.2423373460769653],\n",
       "    'husband': [-1.0564762353897095, -3.2815122604370117],\n",
       "    'woman': [-0.8304060697555542, -3.26839542388916],\n",
       "    'afterward': [-0.09491071850061417, -1.8334558010101318],\n",
       "    'killeth': [-0.9728025197982788, -0.7959017157554626]}},\n",
       "  'nt': {'vec': [0.003617662936449051, 0.0167873352766037],\n",
       "   'sim': {'betrayed': [1.6228442192077637, -1.494047999382019],\n",
       "    'blasphemeth': [-0.27698373794555664, -0.19412018358707428],\n",
       "    'spoil': [-0.769008457660675, 1.0459994077682495],\n",
       "    'levi': [0.2933425009250641, -1.0875442028045654],\n",
       "    'goeth': [1.4728245735168457, 2.8792474269866943]}},\n",
       "  'q': {'vec': [0.8573643565177917, 1.6569138765335083],\n",
       "   'sim': {'trouble': [0.004394938237965107, 1.7567278146743774],\n",
       "    'toucheth': [-0.24976572394371033, 0.5718258023262024],\n",
       "    'unchaste': [0.2778450846672058, -0.12122061103582382],\n",
       "    'crieth': [-0.2559581995010376, 0.579895555973053],\n",
       "    'concealed': [-0.1727008819580078, -1.203569769859314]}}},\n",
       " 'woman': {'ot': {'vec': [-0.8304060697555542, -3.26839542388916],\n",
       "   'sim': {'wife': [0.3871041536331177, -5.489019870758057],\n",
       "    'pang': [-1.3141967058181763, 0.8554126024246216],\n",
       "    'husband': [-1.0564762353897095, -3.2815122604370117],\n",
       "    'esther': [0.7937734723091125, -2.224968910217285],\n",
       "    'concubine': [2.396595001220703, -0.48659002780914307]}},\n",
       "  'nt': {'vec': [2.2203288078308105, 0.801784098148346],\n",
       "   'sim': {'purity': [-0.33095476031303406, -0.39208340644836426],\n",
       "    'dishonoureth': [-0.09795654565095901, 0.022065645083785057],\n",
       "    'seekest': [0.5725338459014893, -0.22060352563858032],\n",
       "    'shorn': [0.41838979721069336, 0.2226550430059433],\n",
       "    'weepest': [0.22372320294380188, -0.11940886825323105]}},\n",
       "  'q': {'vec': [11.728057861328125, 10.886696815490723],\n",
       "   'sim': {'believing': [5.157468318939209, 5.563798904418945],\n",
       "    'slave': [3.3236255645751953, 6.699827671051025],\n",
       "    'marry': [2.364375114440918, 3.256010055541992],\n",
       "    'dower': [5.590217590332031, 7.321133613586426],\n",
       "    'husband': [2.200845718383789, 3.1852023601531982]}}},\n",
       " 'child': {'ot': {'vec': [-0.1409718096256256, -2.64821195602417],\n",
       "   'sim': {'congregation': [-0.19133400917053223, -3.8689794540405273],\n",
       "    'israelitish': [0.22696465253829956, -0.7353507876396179],\n",
       "    'judged': [0.5219211578369141, -2.931701421737671],\n",
       "    'passover': [0.5333852171897888, -3.240689277648926],\n",
       "    'zebaim': [0.8113915324211121, -0.5080983638763428]}},\n",
       "  'nt': {'vec': [-0.44979074597358704, 0.1653110831975937],\n",
       "   'sim': {'birth': [-0.03085457719862461, -0.2746589183807373],\n",
       "    'parent': [-1.5082615613937378, -0.9704762697219849],\n",
       "    'bondage': [-1.5675601959228516, -0.6794626712799072],\n",
       "    'young': [2.6119496822357178, 0.451376736164093],\n",
       "    'born': [-0.8919664621353149, -0.5009564757347107]}},\n",
       "  'q': {'vec': [2.252650737762451, 4.649058818817139],\n",
       "   'sim': {'inheritance': [1.2857329845428467, 2.851260185241699],\n",
       "    'israel': [1.3446190357208252, -3.1651322841644287],\n",
       "    'share': [0.9883327484130859, 5.255621433258057],\n",
       "    'sister': [1.251939296722412, 3.557363510131836],\n",
       "    'suckle': [0.7023863792419434, 1.802039623260498]}}},\n",
       " 'eat': {'ot': {'vec': [-1.9705489873886108, -1.8696054220199585],\n",
       "   'sim': {'eaten': [-2.9946186542510986, 0.4389176070690155],\n",
       "    'ass': [1.2704675197601318, 1.3117518424987793],\n",
       "    'idleness': [-0.7656577229499817, 0.13441608846187592],\n",
       "    'satisfied': [-3.4520246982574463, 1.2288323640823364],\n",
       "    'contemptible': [-0.37619492411613464, -0.27289652824401855]}},\n",
       "  'nt': {'vec': [0.5169417262077332, 1.9896310567855835],\n",
       "   'sim': {'unwashen': [-0.10269785672426224, 0.12907551229000092],\n",
       "    'bread': [0.7303709983825684, 0.4041714072227478],\n",
       "    'unleavened': [1.1741600036621094, -0.20095570385456085],\n",
       "    'meat': [-0.9715390205383301, 2.5288805961608887],\n",
       "    'drink': [-0.2524857223033905, 3.2838056087493896]}},\n",
       "  'q': {'vec': [-2.9958698749542236, 7.678139686584473],\n",
       "   'sim': {'meat': [-1.4091819524765015, 3.6616172790527344],\n",
       "    'food': [-2.354466199874878, 5.4002509117126465],\n",
       "    'drink': [-5.773741722106934, 6.256641864776611],\n",
       "    'waste': [-0.26470664143562317, 1.0202503204345703],\n",
       "    'provided': [0.3570050895214081, 5.8655619621276855]}}}}"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize around each chosen word...\n",
    "for t in topic_vecs:\n",
    "    rel_data = topic_vecs[t]\n",
    "    for d in rel_data:\n",
    "        vecs = rel_data[d]\n",
    "        \n",
    "        # this is what you'll normalize around\n",
    "        topic_vec = vecs['vec']\n",
    "        zero_vec = np.zeros(len(topic_vec))\n",
    "        \n",
    "        transform_vec = zero_vec - topic_vec\n",
    "        \n",
    "        closest = vecs['sim'] \n",
    "        for word in closest:\n",
    "            \n",
    "            # grab the original vector\n",
    "            og_sim_vec = closest[word]\n",
    "            \n",
    "            # transform the vector so it's centered around the current topic\n",
    "            transformed_sim_vec = og_sim_vec + transform_vec\n",
    "            \n",
    "            # reassign the transformed vector\n",
    "            closest[word] = list(transformed_sim_vec)\n",
    "        \n",
    "        # finally, reassign the original vector...\n",
    "        vecs['vec'] = list(zero_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'god': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'lord': [0.07439398765563965, 0.6527481079101562],\n",
       "    'worship': [1.0949894189834595, 1.8250597715377808],\n",
       "    'worshipped': [3.7053232192993164, 0.9215655326843262],\n",
       "    'jealous': [0.5541350841522217, 1.0808217525482178],\n",
       "    'sworn': [0.0332789421081543, -0.3812119960784912]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'amen': [-0.35529327392578125, -0.09023255109786987],\n",
       "    'saviour': [-0.4602508544921875, -0.7353308796882629],\n",
       "    'sceptre': [1.6710811853408813, 0.8696130812168121],\n",
       "    'salvation': [-1.8492159843444824, -1.4663373827934265],\n",
       "    'fellowship': [0.553081750869751, -0.7466008067131042]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'worship': [5.612269759178162, 1.0093111991882324],\n",
       "    'centre': [1.484202615916729, 2.3626431226730347],\n",
       "    'fashion': [1.1478226780891418, 3.2872742116451263],\n",
       "    'idol': [1.3162903040647507, 4.217291414737701],\n",
       "    'passion': [1.4657179452478886, 3.199876219034195]}}},\n",
       " 'heaven': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'fowl': [2.101652979850769, 3.3278846740722656],\n",
       "    'air': [1.8600057363510132, 0.5226355791091919],\n",
       "    'dew': [1.3481552600860596, 3.4316015243530273],\n",
       "    'herewith': [3.0465405583381653, -1.1238768994808197],\n",
       "    'lap': [3.2434152960777283, -0.07325494289398193]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'passion': [-1.9973710924386978, -3.682912480086088],\n",
       "    'earthquake': [1.8188198804855347, -1.2099661827087402],\n",
       "    'lightning': [-0.0042552947998046875, -1.5738115310668945],\n",
       "    'thunderings': [-0.7842772006988525, -2.532897472381592],\n",
       "    'sware': [-2.4550259709358215, -2.8972784280776978]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'established': [1.5434858798980713, -0.4550124406814575],\n",
       "    'proportion': [0.6849677562713623, 3.1816108226776123],\n",
       "    'belongeth': [2.292254865169525, 1.3592260256409645],\n",
       "    'creator': [2.164459466934204, 1.44926911406219],\n",
       "    'creature': [1.486793875694275, 3.6731178760528564]}}},\n",
       " 'hell': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'scourge': [2.0911829471588135, -2.621043026447296],\n",
       "    'overflowing': [1.7760369777679443, 0.2421276569366455],\n",
       "    'lowest': [2.7809780836105347, -2.7682583928108215],\n",
       "    'heapeth': [2.8288581371307373, -3.8034189343452454],\n",
       "    'tossed': [2.7380396127700806, -3.2347764372825623]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'quenched': [-1.1412995606660843, -1.8997254371643066],\n",
       "    'offend': [-2.662020683288574, 1.7523787021636963],\n",
       "    'raiment': [0.6381130218505859, 0.8236634731292725],\n",
       "    'hanged': [-0.8390773385763168, -2.238520860671997],\n",
       "    'pluck': [-1.479630023241043, -2.3942359685897827]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'abode': [-0.17102716863155365, -0.9508626461029053],\n",
       "    'an': [0.1696091927587986, -0.6027599573135376],\n",
       "    'destination': [0.9457262605428696, -0.631014883518219],\n",
       "    'burn': [0.385948583483696, -0.3503001630306244],\n",
       "    'misery': [-0.4260012060403824, -0.7782151401042938]}}},\n",
       " 'love': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'guide': [0.9915038347244263, 0.9062061533331871],\n",
       "    'alienated': [2.0245513319969177, 0.23882651329040527],\n",
       "    'simplicity': [1.8456119894981384, 0.48232144117355347],\n",
       "    'hateth': [0.48345160484313965, 0.2209809422492981],\n",
       "    'forsaketh': [0.9733060598373413, -0.010922431945800781]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'bowel': [2.416904330253601, 0.11695010960102081],\n",
       "    'brotherly': [2.565874695777893, -0.24519577622413635],\n",
       "    'unfeigned': [3.2299522757530212, -0.14066874980926514],\n",
       "    'commendeth': [2.9890166521072388, 0.013846993446350098],\n",
       "    'kindness': [1.9538965225219727, -0.16863849759101868]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'hatred': [-2.1232681274414062, -4.1675518453121185],\n",
       "    'anchorite': [-3.9685394763946533, -3.636833019554615],\n",
       "    'priest': [-4.012653321027756, -3.681282342178747],\n",
       "    'manifold': [-3.91143798828125, -2.2369459867477417],\n",
       "    'substance': [-3.4294554591178894, 1.1105585098266602]}}},\n",
       " 'hate': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'liftest': [2.853190630674362, 2.376623272895813],\n",
       "    'rewarded': [2.1620171070098877, 1.1631826162338257],\n",
       "    'preserveth': [2.2982229590415955, 2.045346349477768],\n",
       "    'puffeth': [2.246908724308014, 2.062828689813614],\n",
       "    'hardeneth': [2.5649527311325073, 2.3262447342276573]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'mammon': [0.7751657962799072, -0.3179086893796921],\n",
       "    'nicolaitans': [1.7019850015640259, -0.5720177516341209],\n",
       "    'enemy': [1.3730637431144714, 1.2789498567581177],\n",
       "    'despitefully': [1.4866997599601746, -0.6409476399421692],\n",
       "    'unthankful': [1.050126314163208, -0.33160585165023804]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'assert': [-0.3296809792518616, -0.1577308177947998],\n",
       "    'christian': [2.8803648352622986, -1.4968187808990479],\n",
       "    'did': [-0.32756584882736206, 0.31929218769073486],\n",
       "    'upon': [-0.3408688008785248, 0.7764483690261841],\n",
       "    'doctrine': [-0.5238826274871826, 0.7728772163391113]}}},\n",
       " 'free': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'maidservant': [0.9196979999542236, 1.81170654296875],\n",
       "    'manservant': [1.2162126302719116, 1.891411006450653],\n",
       "    'wage': [-1.4103310108184814, 3.756749212741852],\n",
       "    'serving': [-1.014048308134079, 1.7419648170471191],\n",
       "    'betrothed': [-0.5015563070774078, 2.0221800804138184]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'justification': [0.7988090515136719, 1.3902199268341064],\n",
       "    'duty': [1.134503185749054, 1.701180338859558],\n",
       "    'liberty': [-0.5838501453399658, 0.7001855373382568],\n",
       "    'debt': [1.3172441720962524, 1.6473572850227356],\n",
       "    'deacon': [1.2573076486587524, 1.3918770849704742]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'want': [-0.8030266463756561, -1.5685005187988281],\n",
       "    'slave': [2.1363441944122314, -0.005192756652832031],\n",
       "    'manner': [-0.04312896728515625, -4.210814952850342],\n",
       "    '´iddat': [-0.4155536890029907, -4.561830520629883],\n",
       "    'handsome': [-1.4308776557445526, -5.191078782081604]}}},\n",
       " 'light': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'darkness': [-2.5300779342651367, 2.1383026838302612],\n",
       "    'obscurity': [2.01654314994812, 0.3495347499847412],\n",
       "    'noonday': [0.05645179748535156, 1.4914510846138],\n",
       "    'shining': [2.137836754322052, 2.194515824317932],\n",
       "    'shineth': [2.5599115043878555, 0.9139042794704437]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'shine': [0.13506445288658142, -2.927192211151123],\n",
       "    'darkness': [0.2288474142551422, -0.2703056335449219],\n",
       "    'candle': [1.3012255728244781, -1.5117745399475098],\n",
       "    'bushel': [0.7583668231964111, -3.4184358716011047],\n",
       "    'lighten': [0.4212782494723797, -4.143247097730637]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'darkness': [-4.010187983512878, -2.679381012916565],\n",
       "    'depth': [-2.04595410823822, -2.9715631008148193],\n",
       "    'lit': [-0.1378079652786255, -0.6908501982688904],\n",
       "    'lamp': [-2.103829264640808, -1.3831241428852081],\n",
       "    'containing': [1.456062838435173, -1.661717414855957]}}},\n",
       " 'darkness': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'obscurity': [4.546621084213257, -1.78876793384552],\n",
       "    'light': [2.5300779342651367, -2.1383026838302612],\n",
       "    'shadow': [0.8820104598999023, 3.2603620290756226],\n",
       "    'noonday': [2.5865297317504883, -0.6468515992164612],\n",
       "    'cloud': [2.04355788230896, 2.0014039278030396]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'light': [-0.2288474142551422, 0.2703056335449219],\n",
       "    'shine': [-0.09378296136856079, -2.656886577606201],\n",
       "    'mist': [0.7719282507896423, -3.181136131286621],\n",
       "    'bushel': [0.5295194089412689, -3.148130238056183],\n",
       "    'blackness': [1.1117433309555054, -3.219478964805603]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'depth': [1.9642338752746582, -0.2921820878982544],\n",
       "    'light': [4.010187983512878, 2.679381012916565],\n",
       "    'lamp': [1.9063587188720703, 1.2962568700313568],\n",
       "    'billow': [3.565446376800537, 1.0549764037132263],\n",
       "    'topped': [3.595785975456238, 1.0641024112701416]}}},\n",
       " 'peace': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'imputed': [0.131253182888031, 1.7669654488563538],\n",
       "    'sacrifice': [-1.2708608508110046, 0.08151459693908691],\n",
       "    'freewill': [0.7864189073443413, 0.6260803937911987],\n",
       "    'pertain': [-0.07686668634414673, 2.091376632452011],\n",
       "    'heave': [2.571913182735443, 1.4745545387268066]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'adjure': [0.05187059938907623, 0.6490103602409363],\n",
       "    'direct': [-0.11990982294082642, 1.046964943408966],\n",
       "    'unity': [-0.3014613687992096, 1.2691459953784943],\n",
       "    'held': [1.9497015178203583, -0.831852912902832],\n",
       "    'preserved': [-0.3609504997730255, 0.9388136863708496]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'salutation': [-1.8958107978105545, -0.5288825333118439],\n",
       "    'guarantee': [-1.956441342830658, -0.7547102123498917],\n",
       "    'withdraw': [-2.238727793097496, -0.7360751032829285],\n",
       "    'rewarded': [-1.7199490666389465, -0.006113171577453613],\n",
       "    'exile': [0.9534702301025391, 0.30113983154296875]}}},\n",
       " 'war': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'battle': [-1.19293874502182, 0.11363554000854492],\n",
       "    'band': [-0.5038883239030838, 2.8732503056526184],\n",
       "    'valour': [4.478041708469391, 0.7065305709838867],\n",
       "    'fighting': [-0.8530758768320084, 1.6384781301021576],\n",
       "    'fight': [-1.8319275975227356, 0.2156074047088623]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'rumour': [1.5227298587560654, -2.44606414437294],\n",
       "    'fold': [1.4664270877838135, -2.1714288517832756],\n",
       "    'incorruption': [0.6727316975593567, -1.2623878717422485],\n",
       "    'soweth': [-0.28137755393981934, 0.25211524963378906],\n",
       "    'incorruptible': [0.5821840167045593, -1.0529807806015015]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'thoroughly': [-2.63073068857193, -3.8183757662773132],\n",
       "    'subdued': [-2.317792594432831, -3.8806938230991364],\n",
       "    'captive': [-1.0603358745574951, -2.5872199535369873],\n",
       "    'lagged': [-1.8556538820266724, -3.4997576475143433],\n",
       "    'vehement': [-2.390125811100006, -4.200042635202408]}}},\n",
       " 'life': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'seek': [-2.0590243339538574, 0.5673666000366211],\n",
       "    'handmaid': [1.431312084197998, -0.8994724750518799],\n",
       "    'eatest': [2.4161768555641174, 2.6069012880325317],\n",
       "    'juniper': [2.188581943511963, 3.698152720928192],\n",
       "    'sought': [2.5956350937485695, -1.4962084293365479]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'everlasting': [0.029998779296875, -0.7707222700119019],\n",
       "    'eternal': [-0.5261602401733398, -2.0369876325130463],\n",
       "    'reapeth': [1.6462846994400024, -1.7262598276138306],\n",
       "    'endureth': [1.488431692123413, -1.3891366720199585],\n",
       "    'callest': [2.4422374963760376, -2.338965798728168]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'amusement': [-0.6392483413219452, -0.6179246306419373],\n",
       "    'world': [-0.6285109221935272, -1.2022134363651276],\n",
       "    'present': [-0.2089148312807083, -0.7568693161010742],\n",
       "    'play': [-0.48259618878364563, -1.6553637385368347],\n",
       "    'convenience': [-0.9531103372573853, 0.19709575176239014]}}},\n",
       " 'death': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'die': [-1.795136570930481, -1.3023526668548584],\n",
       "    'hid': [0.08881986141204834, 2.327625662088394],\n",
       "    'worthy': [1.189845621585846, 1.2398847341537476],\n",
       "    'leper': [2.808279037475586, 3.2995442152023315],\n",
       "    'killeth': [1.0151419639587402, 1.459593117237091]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'taste': [1.2006293907761574, -0.300920806825161],\n",
       "    'point': [0.8973687142133713, -0.2974950894713402],\n",
       "    'testator': [0.6876918375492096, 0.2260429933667183],\n",
       "    'translated': [0.6124347150325775, -0.22110816091299057],\n",
       "    'immortality': [0.33103054761886597, 0.5768909528851509]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'bequest': [1.5902910232543945, 2.3203462958335876],\n",
       "    'purge': [1.2049828618764877, 1.122842699289322],\n",
       "    'die': [-0.9288630485534668, 3.2528598308563232],\n",
       "    'decreed': [0.2342439889907837, 1.4936135038733482],\n",
       "    'reply': [1.1337895430624485, -0.9009991884231567]}}},\n",
       " 'man': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'men': [1.3637606501579285, 0.4157367944717407],\n",
       "    'husband': [0.6833114624023438, -1.6234381198883057],\n",
       "    'woman': [0.909381628036499, -1.610321283340454],\n",
       "    'afterward': [1.644876979291439, -0.17538166046142578],\n",
       "    'killeth': [0.7669851779937744, 0.8621724247932434]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'betrayed': [1.6192265562713146, -1.5108353346586227],\n",
       "    'blasphemeth': [-0.2806014008820057, -0.21090751886367798],\n",
       "    'spoil': [-0.7726261205971241, 1.0292120724916458],\n",
       "    'levi': [0.28972483798861504, -1.1043315380811691],\n",
       "    'goeth': [1.4692069105803967, 2.8624600917100906]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'trouble': [-0.8529694182798266, 0.09981393814086914],\n",
       "    'toucheth': [-1.107130080461502, -1.085088074207306],\n",
       "    'unchaste': [-0.5795192718505859, -1.7781344875693321],\n",
       "    'crieth': [-1.1133225560188293, -1.0770183205604553],\n",
       "    'concealed': [-1.0300652384757996, -2.8604836463928223]}}},\n",
       " 'woman': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'wife': [1.2175102233886719, -2.2206244468688965],\n",
       "    'pang': [-0.48379063606262207, 4.123808026313782],\n",
       "    'husband': [-0.22607016563415527, -0.013116836547851562],\n",
       "    'esther': [1.6241795420646667, 1.043426513671875],\n",
       "    'concubine': [3.2270010709762573, 2.781805396080017]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'purity': [-2.5512835681438446, -1.1938675045967102],\n",
       "    'dishonoureth': [-2.3182853534817696, -0.7797184530645609],\n",
       "    'seekest': [-1.6477949619293213, -1.0223876237869263],\n",
       "    'shorn': [-1.8019390106201172, -0.5791290551424026],\n",
       "    'weepest': [-1.9966056048870087, -0.921192966401577]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'believing': [-6.570589542388916, -5.322897911071777],\n",
       "    'slave': [-8.40443229675293, -4.186869144439697],\n",
       "    'marry': [-9.363682746887207, -7.6306867599487305],\n",
       "    'dower': [-6.137840270996094, -3.565563201904297],\n",
       "    'husband': [-9.527212142944336, -7.701494455337524]}}},\n",
       " 'child': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'congregation': [-0.050362199544906616, -1.2207674980163574],\n",
       "    'israelitish': [0.36793646216392517, 1.912861168384552],\n",
       "    'judged': [0.6628929674625397, -0.283489465713501],\n",
       "    'passover': [0.6743570268154144, -0.5924773216247559],\n",
       "    'zebaim': [0.9523633420467377, 2.140113592147827]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'birth': [0.4189361687749624, -0.439970001578331],\n",
       "    'parent': [-1.0584708154201508, -1.1357873529195786],\n",
       "    'bondage': [-1.1177694499492645, -0.8447737544775009],\n",
       "    'young': [3.061740428209305, 0.28606565296649933],\n",
       "    'born': [-0.4421757161617279, -0.6662675589323044]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'inheritance': [-0.9669177532196045, -1.7977986335754395],\n",
       "    'israel': [-0.908031702041626, -7.814191102981567],\n",
       "    'share': [-1.2643179893493652, 0.606562614440918],\n",
       "    'sister': [-1.000711441040039, -1.0916953086853027],\n",
       "    'suckle': [-1.5502643585205078, -2.8470191955566406]}}},\n",
       " 'eat': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'eaten': [-1.0240696668624878, 2.308523029088974],\n",
       "    'ass': [3.2410165071487427, 3.181357264518738],\n",
       "    'idleness': [1.2048912644386292, 2.0040215104818344],\n",
       "    'satisfied': [-1.4814757108688354, 3.098437786102295],\n",
       "    'contemptible': [1.5943540632724762, 1.59670889377594]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'unwashen': [-0.6196395829319954, -1.8605555444955826],\n",
       "    'bread': [0.2134292721748352, -1.5854596495628357],\n",
       "    'unleavened': [0.6572182774543762, -2.1905867606401443],\n",
       "    'meat': [-1.4884807467460632, 0.5392495393753052],\n",
       "    'drink': [-0.7694274485111237, 1.2941745519638062]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'meat': [1.5866879224777222, -4.016522407531738],\n",
       "    'food': [0.6414036750793457, -2.277888774871826],\n",
       "    'drink': [-2.77787184715271, -1.4214978218078613],\n",
       "    'waste': [2.7311632335186005, -6.657889366149902],\n",
       "    'provided': [3.3528749644756317, -1.812577724456787]}}}}"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "word {\n",
    "    \"ot\": [],\n",
    "    \"nt\"\n",
    "}\n",
    "\"\"\"\n",
    "polygon_data = {}\n",
    "\n",
    "for t in topic_vecs:\n",
    "    \n",
    "    rel_data = topic_vecs[t]\n",
    "    polygon_data[t] = {}\n",
    "    \n",
    "    for d in rel_data:\n",
    "        vecs = rel_data[d]\n",
    "        \n",
    "        ref_vec = vecs['vec']\n",
    "        sim_vecs = list(vecs['sim'].items())\n",
    "                \n",
    "        polygon_data[t][d] = {\n",
    "            \"poly\": g.Polygon([(v[1][0], v[1][1]) for v in sim_vecs]),\n",
    "            \"words\": [v[0] for v in sim_vecs]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating polygon / DXF data\n",
      "god\n",
      "heaven\n",
      "hell\n",
      "love\n",
      "hate\n",
      "free\n",
      "light\n",
      "darkness\n",
      "peace\n",
      "war\n",
      "life\n",
      "death\n",
      "man\n",
      "woman\n",
      "child\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating polygon / DXF data\")\n",
    "\n",
    "for topic in polygon_data:\n",
    "    \n",
    "    print(topic)\n",
    "    all_meta = polygon_data[topic]\n",
    "    \n",
    "    for rel in all_meta:\n",
    "        \n",
    "        # grab the specific religions meta data\n",
    "        rel_meta = all_meta[rel]\n",
    "        \n",
    "        # all the words\n",
    "        rel_words = rel_meta['words']\n",
    "        \n",
    "        # grab the convex hull and regular polygon data \n",
    "        rel_convex = list(rel_meta['poly'].convex_hull.exterior.coords)\n",
    "        rel_poly = list(rel_meta['poly'].exterior.coords)\n",
    "        \n",
    "        \n",
    "        #####################################\n",
    "        # DXF \n",
    "        #####################################\n",
    "        \n",
    "        # CONFIGURE THE FILE PATHS FOR SAVING\n",
    "        folder_path = '../data/analyzed/dxf/religion-specific/{}'.format(topic)\n",
    "\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.mkdir(folder_path)\n",
    "            \n",
    "        drawing = dxf.drawing('../data/analyzed/dxf/religion-specific/{}/{}-{}.dxf'.format(topic,topic,rel))\n",
    "        \n",
    "        line = dxf.polyline(linetype='DOT', layer ='INTERNAL')\n",
    "        outline = dxf.polyline(linetype='CONTINUOUS', layer = 'OUTLINE')\n",
    "        line.add_vertices(rel_poly)\n",
    "        outline.add_vertices(rel_convex)\n",
    "        \n",
    "        text_layer = dxf.layer('TEXT')\n",
    "        drawing.layers.add(text_layer)\n",
    "\n",
    "        # ADD THE TEXT\n",
    "        for p in zip(rel_words, rel_poly):\n",
    "            t = dxf.text(p[0], p[1], height=0.05, rotation=0, layer = 'TEXT')\n",
    "            drawing.add(t)\n",
    "            \n",
    "        # Close the lines\n",
    "        outline.close()\n",
    "        line.close()\n",
    "        \n",
    "        drawing.add(outline)\n",
    "        drawing.add(line)\n",
    "        drawing.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
