{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from itertools import chain, combinations\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import smart_open, simple_preprocess\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.level = logging.INFO  # ipython sometimes messes up the logging setup; restore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "Getting the data from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_df = pd.read_csv(\"../data/old-testament-verses.csv\")\n",
    "nt_df = pd.read_csv(\"../data/new-testament-verses.csv\")\n",
    "\n",
    "#rename from AyahText to VerseText\n",
    "q_df = pd.read_csv(\"../data/quran-verses.csv\")\n",
    "q_df.columns = ['DatabaseID', 'SuraID', 'VerseID', 'VerseText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(df):\n",
    "    return list(df[\"VerseText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stops = [w for w in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the stop words the most common words...?\n",
    "new_stops = ['hath', \"'s\",'an', 'let','behold', 'went','o','hast','thine','like','thing','things','quot','and', 'in', 'thou', 'thee', 'thy', 'unto', 'ye', 'said', 'saith', 'shall', 'shalt', 'yea', 'thereof']\n",
    "all_stops += new_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "regex = re.compile('[%s]' % re.escape(punctuation))\n",
    "\n",
    "def strip_punc(s):  # From Vinko's solution, with fix.\n",
    "    return regex.sub('', s)\n",
    "\n",
    "def clean_text(text):\n",
    "    # basic nlp clean up\n",
    "    lm = WordNetLemmatizer()\n",
    "    st = SnowballStemmer(\"english\")\n",
    "\n",
    "    base = [strip_punc(t).lower() for t in word_tokenize(text)\n",
    "            if t not in punctuation\n",
    "            and t.lower() not in all_stops]\n",
    "    \n",
    "    lemmatized = [lm.lemmatize(w) for w in base]\n",
    "#     stemmed = [st.stem(w) for w in lemmatized]\n",
    "    no_chars = [w for w in lemmatized if len(w) > 1]\n",
    "    \n",
    "    return no_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab preparation\n",
    "\n",
    "Constructing a holistic Doc2Vec model for all of the texts put together. Basically, this is just Word2Vec but tagging each word with which religion it belongs to (according to a probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(df):\n",
    "    vocab = []\n",
    "    for l in get_lines(df):\n",
    "        tokens = tokenize(l)\n",
    "        vocab += tokens\n",
    "    return set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shared(sets):\n",
    "    # Finds the intersection of all the input sets\n",
    "    return reduce((lambda set1,set2: set1&set2), sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sym_diffs(sets):\n",
    "    # Finds the symm etric difference of a list of sets\n",
    "    return reduce((lambda set1, set2: set1.symmetric_difference(set2)), sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_uniques(sets):\n",
    "    # Gets the unique elements in each set\n",
    "    # return a dictionary with labels of each\n",
    "    intersection = get_shared(sets)\n",
    "    sym_diffs = get_sym_diffs(sets)\n",
    "    return sym_diffs - intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_vocabs(vocabs_dict):\n",
    "    all_uniques = get_all_uniques(vocabs_dict.values())\n",
    "    unique_dict = {}\n",
    "    \n",
    "    for tag, vocab in vocabs_dict.items():\n",
    "        unique_dict[tag] = []\n",
    "        for w in vocab:\n",
    "            if w in all_uniques:\n",
    "                unique_dict[tag].append(w)\n",
    "    \n",
    "    return unique_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict(vocab, tag):\n",
    "    d = {}\n",
    "    for w in vocab:\n",
    "        d[w] = tag\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(dicts): \n",
    "    super_dict = {}\n",
    "    for d in dicts:\n",
    "        for k, v in d.items():\n",
    "            super_dict[k] = v\n",
    "    return super_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_common(l1,l2):\n",
    "    result = False\n",
    "    for x in l1: \n",
    "        for y in l2: \n",
    "            if x == y:\n",
    "                print(\"Got same:\", x, y)\n",
    "                result = True\n",
    "                return result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Word2Vec attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(l):\n",
    "    lmin = min(l)\n",
    "    lmax = max(l)\n",
    "    return [(v-lmin)/(lmax-lmin) for v in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(d, rev):\n",
    "    return sorted(d.items(), key=lambda kv: kv[1], reverse=rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec_docs(df):\n",
    "    verses = list(df[\"VerseText\"])\n",
    "    docs = [clean_text(v) for v in verses]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_origin(model, origin_word):\n",
    "    \n",
    "    # gets the original vector for the chosen origin word\n",
    "    origin_vec = model.wv.get_vector(origin_word)\n",
    "    \n",
    "    # used to calculate the new origin\n",
    "    zero_vec = np.zeros(origin_vec.shape)\n",
    "    \n",
    "    # vector to shift each point by everything by\n",
    "    transformation_vec = zero_vec - origin_vec\n",
    "    \n",
    "    # dict to store all the new vectors\n",
    "    transformed_vecs = {}\n",
    "    \n",
    "    for w in model.wv.vocab:\n",
    "        # original vector for the word\n",
    "        w_vec = model.wv.get_vector(w)\n",
    "        \n",
    "        # shifted by the transformation\n",
    "        transformed_w_vec = w_vec + transformation_vec\n",
    "        \n",
    "        # store\n",
    "        transformed_vecs[w] = transformed_w_vec\n",
    "        \n",
    "    return transformed_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the documents from each text.\n",
    "ot_docs = get_word2vec_docs(ot_df)\n",
    "nt_docs = get_word2vec_docs(nt_df)\n",
    "q_docs = get_word2vec_docs(q_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global hyper parameters\n",
    "hp = {\n",
    "    \"size\": 150, # size of the one-hot-encoded word vectors\n",
    "    \"window\": 20, # context size\n",
    "    \"min_count\": 2,\n",
    "    \"workers\": 4,\n",
    "    \"iter\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(docs):\n",
    "    model = gensim.models.Word2Vec(\n",
    "        docs,\n",
    "        size=hp[\"size\"],\n",
    "        window=hp[\"window\"],\n",
    "        min_count=hp[\"min_count\"],\n",
    "        workers=hp[\"workers\"])\n",
    "    \n",
    "    # initialize similarities\n",
    "    model.train(docs, total_examples=len(docs), epochs=50)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning models to compare similar words across religions\n",
    "\n",
    "Note that for the new Gensim versions, calls for .index2word, .vocab, .syn0 and .syn0norm should be replaced with .wv.index2word, .wv.vocab, .wv.syn0 and .wv.syn0norm respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_align_gensim(models, words=None):\n",
    "    \"\"\"\n",
    "    Intersect three gensim word2vec models, m1 and m2.\n",
    "    Generalized from original two-way intersection.\n",
    "    \n",
    "    Only the shared vocabulary between them is kept.\n",
    "    If 'words' is set (as list or set), then the vocabulary is intersected with this list as well.\n",
    "    Indices are re-organized from 0..N in order of descending frequency (=sum of counts from both m1 and m2).\n",
    "    These indices correspond to the new syn0 and syn0norm objects in both gensim models:\n",
    "        -- so that Row 0 of m1.syn0 will be for the same word as Row 0 of m2.syn0\n",
    "        -- you can find the index of any word on the .index2word list: model.index2word.index(word) => 2\n",
    "    The .vocab dictionary is also updated for each model, preserving the count but updating the index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the vocab for each model\n",
    "    vocabs = [set(m.wv.vocab.keys()) for m in models]\n",
    "\n",
    "    # Find the common vocabulary\n",
    "    common_vocab = reduce((lambda vocab1,vocab2: vocab1&vocab2), vocabs)\n",
    "    if words: common_vocab&=set(words)\n",
    "\n",
    "    # If no alignment necessary because vocab is identical...\n",
    "    \n",
    "    # This was generalized from:\n",
    "    # if not vocab_m1-common_vocab and not vocab_m2-common_vocab and not vocab_m3-common_vocab:\n",
    "    #   return (m1,m2,m3)\n",
    "    if all(not vocab-common_vocab for vocab in vocabs):\n",
    "        print(\"All identical!\")\n",
    "        return models\n",
    "        \n",
    "    # Otherwise sort by frequency (summed for both)\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: sum([m.wv.vocab[w].count for m in models]),reverse=True)\n",
    "    \n",
    "    # Then for each model...\n",
    "    for m in models:\n",
    "        \n",
    "        # Replace old vectors_norm array with new one (with common vocab)\n",
    "        indices = [m.wv.vocab[w].index for w in common_vocab]\n",
    "                \n",
    "        old_arr = m.wv.vectors_norm\n",
    "                \n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.vectors_norm = m.wv.syn0 = new_arr\n",
    "\n",
    "        # Replace old vocab dictionary with new one (with common vocab)\n",
    "        # and old index2word with new one\n",
    "        m.wv.index2word = common_vocab\n",
    "        old_vocab = m.wv.vocab\n",
    "        new_vocab = {}\n",
    "        for new_index,word in enumerate(common_vocab):\n",
    "            old_vocab_obj=old_vocab[word]\n",
    "            new_vocab[word] = gensim.models.word2vec.Vocab(index=new_index, count=old_vocab_obj.count)\n",
    "        m.wv.vocab = new_vocab\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nExample usage:\\nmodel1 = [a gensim model I have for text published in the 1750s]\\nmodel2 = [a gensim model I have for text published in the 1850s]\\n# The word \\'god\\' does not change much in meaning:\\n    In [61]: measure_semantic_shift_by_neighborhood(model1,model2,\\'god\\',k=10,verbose=True)\\n    \\n    >> Neighborhood of associations of the word \"god\" in model1:\\n    almighty, jehovah, creator, uncreated, omniscient, logos, righteousness, christ, redeemer, salvation\\n    >> Neighborhood of associations of the word \"god\" in model2:\\n    almighty, heaven, jehovah, creator, redeemer, christ, divine, righteousness, providence, saviour\\n    \\n    Out[61]: 0.011609088245951749\\n# The word \\'matter\\' does, moving from meaning mainly the \"matter\" of the universe to \"what is the matter\":\\n    In [62]: measure_semantic_shift_by_neighborhood(model1,model2,\\'matter\\',k=10,verbose=True)\\n    \\n    >> Neighborhood of associations of the word \"matter\" in model1:\\n    cohesion, sediment, menstruum, purulent, conceivable, gelatinous, morbific, compression, cerebellum, divisible\\n    >> Neighborhood of associations of the word \"matter\" in model2:\\n    matters, question, subject, affair, substance, concernment, concerns, questions, controversy, discussion\\n    \\n    Out[62]: 0.0847526073498025\\n# The word \\'station\\' changes even more, moving from meaning one\\'s social rank or \"station\", to a train station:\\n    In [63]: measure_semantic_shift_by_neighborhood(model1,model2,\\'station\\',k=10,verbose=True)\\n    \\n    >> Neighborhood of associations of the word \"station\" in model1:\\n    stations, dation, sphere, employments, deg, vocation, personate, lowest, district, apprenticeship\\n    >> Neighborhood of associations of the word \"station\" in model2:\\n    stations, train, posts, position, situation, town, carriage, stationed, rank, cab\\n    \\n    Out[63]: 0.14173381265358098\\n'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def measure_semantic_shift_by_neighborhood(model1,model2,word,k=25,verbose=False):\n",
    "    \"\"\"\n",
    "    Basic implementation of William Hamilton (@williamleif) et al's measure of semantic change\n",
    "    proposed in their paper \"Cultural Shift or Linguistic Drift?\" (https://arxiv.org/abs/1606.02821),\n",
    "    which they call the \"local neighborhood measure.\" They find this measure better suited to understand\n",
    "    the semantic change of nouns owing to \"cultural shift,\" or changes in meaning \"local\" to that word,\n",
    "    rather than global changes in language (\"linguistic drift\") use that are better suited to a\n",
    "    Procrustes-alignment method (also described in the same paper.)\n",
    "    \n",
    "    Arguments are:\n",
    "    - `model1`, `model2`: Are gensim word2vec models.\n",
    "    - `word` is a sting representation of a given word.\n",
    "    - `k` is the size of the word's neighborhood (# of its closest words in its vector space).\n",
    "    \"\"\"\n",
    "    # Import function for cosine distance\n",
    "    from scipy.spatial.distance import cosine\n",
    "    \n",
    "    # Check that this word is present in both models\n",
    "    if not word in model1.wv.vocab or not word in model2.wv.vocab:\n",
    "        print(\"!! Word %s not present in both models.\" % word)\n",
    "        return None\n",
    "    \n",
    "    # Get the two neighborhoods\n",
    "    neighborhood1 = [w for w,c in model1.most_similar(word,topn=k)]\n",
    "    neighborhood2 = [w for w,c in model2.most_similar(word,topn=k)]\n",
    "    \n",
    "    # Print?\n",
    "    if verbose:\n",
    "        print('>> Neighborhood of associations of the word \"%s\" in model1:' % word)\n",
    "        print(', '.join(neighborhood1))\n",
    "        print('>> Neighborhood of associations of the word \"%s\" in model2:' % word)\n",
    "        print(', '.join(neighborhood2))\n",
    "    \n",
    "    # Get the 'meta' neighborhood (both combined)\n",
    "    meta_neighborhood = list(set(neighborhood1)|set(neighborhood2))\n",
    "    \n",
    "    # Filter the meta neighborhood so that it contains only words present in both models\n",
    "    meta_neighborhood = [w for w in meta_neighborhood if w in model1.wv.vocab and w in model2.wv.vocab]\n",
    "    \n",
    "    # For both models, get a similarity vector between the focus word and all of the words in the meta neighborhood\n",
    "    vector1 = [model1.similarity(word,w) for w in meta_neighborhood]\n",
    "    vector2 = [model2.similarity(word,w) for w in meta_neighborhood]\n",
    "    \n",
    "    # Compute the cosine distance *between* those similarity vectors\n",
    "    dist=cosine(vector1,vector2)\n",
    "    \n",
    "    # Return this cosine distance -- a measure of the relative semantic shift for this word between these two models\n",
    "    return dist\n",
    "    \n",
    "\"\"\"\n",
    "Example usage:\n",
    "model1 = [a gensim model I have for text published in the 1750s]\n",
    "model2 = [a gensim model I have for text published in the 1850s]\n",
    "# The word 'god' does not change much in meaning:\n",
    "    In [61]: measure_semantic_shift_by_neighborhood(model1,model2,'god',k=10,verbose=True)\n",
    "    \n",
    "    >> Neighborhood of associations of the word \"god\" in model1:\n",
    "    almighty, jehovah, creator, uncreated, omniscient, logos, righteousness, christ, redeemer, salvation\n",
    "    >> Neighborhood of associations of the word \"god\" in model2:\n",
    "    almighty, heaven, jehovah, creator, redeemer, christ, divine, righteousness, providence, saviour\n",
    "    \n",
    "    Out[61]: 0.011609088245951749\n",
    "# The word 'matter' does, moving from meaning mainly the \"matter\" of the universe to \"what is the matter\":\n",
    "    In [62]: measure_semantic_shift_by_neighborhood(model1,model2,'matter',k=10,verbose=True)\n",
    "    \n",
    "    >> Neighborhood of associations of the word \"matter\" in model1:\n",
    "    cohesion, sediment, menstruum, purulent, conceivable, gelatinous, morbific, compression, cerebellum, divisible\n",
    "    >> Neighborhood of associations of the word \"matter\" in model2:\n",
    "    matters, question, subject, affair, substance, concernment, concerns, questions, controversy, discussion\n",
    "    \n",
    "    Out[62]: 0.0847526073498025\n",
    "# The word 'station' changes even more, moving from meaning one's social rank or \"station\", to a train station:\n",
    "    In [63]: measure_semantic_shift_by_neighborhood(model1,model2,'station',k=10,verbose=True)\n",
    "    \n",
    "    >> Neighborhood of associations of the word \"station\" in model1:\n",
    "    stations, dation, sphere, employments, deg, vocation, personate, lowest, district, apprenticeship\n",
    "    >> Neighborhood of associations of the word \"station\" in model2:\n",
    "    stations, train, posts, position, situation, town, carriage, stationed, rank, cab\n",
    "    \n",
    "    Out[63]: 0.14173381265358098\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train the models on each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : PROGRESS: at sentence #10000, processed 97904 words, keeping 5861 word types\n",
      "INFO : PROGRESS: at sentence #20000, processed 182562 words, keeping 8873 word types\n",
      "INFO : collected 9377 word types from a corpus of 214613 raw words and 23145 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : min_count=2 retains 6304 unique words (67% of original 9377, drops 3073)\n",
      "INFO : min_count=2 leaves 211540 word corpus (98% of original 214613, drops 3073)\n",
      "INFO : deleting the raw counts dictionary of 9377 items\n",
      "INFO : sample=0.001 downsamples 44 most-common words\n",
      "INFO : downsampling leaves estimated 184285 word corpus (87.1% of prior 211540)\n",
      "INFO : estimated required memory for 6304 words and 150 dimensions: 10716800 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : training model with 4 workers on 6304 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 214613 raw words (184314 effective words) took 0.1s, 1372497 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 214613 raw words (184348 effective words) took 0.1s, 1511131 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 214613 raw words (184415 effective words) took 0.1s, 1416784 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 214613 raw words (184349 effective words) took 0.1s, 1646353 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 214613 raw words (184369 effective words) took 0.1s, 1376222 effective words/s\n",
      "INFO : training on a 1073065 raw words (921795 effective words) took 0.7s, 1357120 effective words/s\n",
      "INFO : precomputing L2-norms of word weight vectors\n",
      "WARNING : Effective 'alpha' higher than previous training cycles\n",
      "INFO : training model with 4 workers on 6304 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 214613 raw words (184335 effective words) took 0.1s, 1333327 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 214613 raw words (184193 effective words) took 0.1s, 1279405 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 214613 raw words (184279 effective words) took 0.1s, 1251497 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 214613 raw words (184310 effective words) took 0.1s, 1472612 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 214613 raw words (184399 effective words) took 0.1s, 1352750 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 6 : training on 214613 raw words (184481 effective words) took 0.1s, 1503743 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 7 : training on 214613 raw words (184312 effective words) took 0.1s, 1423224 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 8 : training on 214613 raw words (184154 effective words) took 0.1s, 1768187 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 9 : training on 214613 raw words (184318 effective words) took 0.1s, 1588528 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 10 : training on 214613 raw words (184153 effective words) took 0.1s, 1670053 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 11 : training on 214613 raw words (184198 effective words) took 0.1s, 1557810 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 12 : training on 214613 raw words (184104 effective words) took 0.1s, 1669369 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 13 : training on 214613 raw words (184313 effective words) took 0.1s, 1447806 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 14 : training on 214613 raw words (184343 effective words) took 0.1s, 1431091 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 15 : training on 214613 raw words (184191 effective words) took 0.1s, 1495515 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 16 : training on 214613 raw words (184247 effective words) took 0.1s, 1623910 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 17 : training on 214613 raw words (184305 effective words) took 0.1s, 1491524 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 18 : training on 214613 raw words (184162 effective words) took 0.1s, 1551840 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 19 : training on 214613 raw words (184185 effective words) took 0.1s, 1717792 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 20 : training on 214613 raw words (184301 effective words) took 0.1s, 1616754 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 21 : training on 214613 raw words (184162 effective words) took 0.1s, 1702512 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 22 : training on 214613 raw words (184360 effective words) took 0.1s, 1848519 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 23 : training on 214613 raw words (184240 effective words) took 0.1s, 1701837 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 24 : training on 214613 raw words (184331 effective words) took 0.1s, 1796918 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 25 : training on 214613 raw words (184384 effective words) took 0.1s, 1802322 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 26 : training on 214613 raw words (184139 effective words) took 0.1s, 1834230 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 27 : training on 214613 raw words (184315 effective words) took 0.1s, 1752728 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 28 : training on 214613 raw words (184307 effective words) took 0.1s, 1626473 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 29 : training on 214613 raw words (184323 effective words) took 0.1s, 1291406 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 30 : training on 214613 raw words (184303 effective words) took 0.1s, 1913279 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 31 : training on 214613 raw words (184206 effective words) took 0.1s, 1852404 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 32 : training on 214613 raw words (184171 effective words) took 0.1s, 1624479 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 33 : training on 214613 raw words (184250 effective words) took 0.1s, 1839841 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 34 : training on 214613 raw words (184420 effective words) took 0.1s, 1885528 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 35 : training on 214613 raw words (184199 effective words) took 0.1s, 1747125 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 36 : training on 214613 raw words (184246 effective words) took 0.1s, 1854841 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 37 : training on 214613 raw words (184365 effective words) took 0.1s, 1866688 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 38 : training on 214613 raw words (184508 effective words) took 0.1s, 1727642 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 39 : training on 214613 raw words (184295 effective words) took 0.1s, 2042801 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 40 : training on 214613 raw words (184231 effective words) took 0.1s, 1901348 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 41 : training on 214613 raw words (184327 effective words) took 0.1s, 1792682 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 42 : training on 214613 raw words (184342 effective words) took 0.1s, 1938065 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 43 : training on 214613 raw words (184208 effective words) took 0.1s, 1967708 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 44 : training on 214613 raw words (184126 effective words) took 0.1s, 1928020 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 45 : training on 214613 raw words (184295 effective words) took 0.1s, 1929390 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 46 : training on 214613 raw words (184295 effective words) took 0.1s, 1953144 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 47 : training on 214613 raw words (184314 effective words) took 0.1s, 1960585 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 48 : training on 214613 raw words (184273 effective words) took 0.1s, 2070036 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 49 : training on 214613 raw words (184086 effective words) took 0.1s, 2060959 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 50 : training on 214613 raw words (184061 effective words) took 0.1s, 1956442 effective words/s\n",
      "INFO : training on a 10730650 raw words (9213365 effective words) took 6.0s, 1539921 effective words/s\n",
      "INFO : precomputing L2-norms of word weight vectors\n",
      "WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : collected 5152 word types from a corpus of 60551 raw words and 7957 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : min_count=2 retains 3417 unique words (66% of original 5152, drops 1735)\n",
      "INFO : min_count=2 leaves 58816 word corpus (97% of original 60551, drops 1735)\n",
      "INFO : deleting the raw counts dictionary of 5152 items\n",
      "INFO : sample=0.001 downsamples 59 most-common words\n",
      "INFO : downsampling leaves estimated 52063 word corpus (88.5% of prior 58816)\n",
      "INFO : estimated required memory for 3417 words and 150 dimensions: 5808900 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : training model with 4 workers on 3417 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 60551 raw words (52038 effective words) took 0.0s, 1418241 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 60551 raw words (52050 effective words) took 0.0s, 1279039 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 60551 raw words (52140 effective words) took 0.0s, 1684121 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 60551 raw words (52084 effective words) took 0.0s, 1728991 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 60551 raw words (52053 effective words) took 0.0s, 1734977 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : training on a 302755 raw words (260365 effective words) took 0.2s, 1256647 effective words/s\n",
      "WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "INFO : precomputing L2-norms of word weight vectors\n",
      "WARNING : Effective 'alpha' higher than previous training cycles\n",
      "INFO : training model with 4 workers on 3417 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 60551 raw words (52043 effective words) took 0.0s, 1660990 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 60551 raw words (51992 effective words) took 0.0s, 1676564 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 60551 raw words (52035 effective words) took 0.0s, 1554998 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 60551 raw words (52017 effective words) took 0.0s, 1764113 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 60551 raw words (52016 effective words) took 0.0s, 1738902 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 6 : training on 60551 raw words (52145 effective words) took 0.0s, 1575568 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 7 : training on 60551 raw words (52013 effective words) took 0.0s, 1721543 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 8 : training on 60551 raw words (52140 effective words) took 0.0s, 1812607 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 9 : training on 60551 raw words (52007 effective words) took 0.0s, 1676920 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 10 : training on 60551 raw words (52080 effective words) took 0.0s, 1670844 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 11 : training on 60551 raw words (52062 effective words) took 0.0s, 1721709 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 12 : training on 60551 raw words (52048 effective words) took 0.0s, 1686736 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 13 : training on 60551 raw words (52014 effective words) took 0.0s, 1734694 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 14 : training on 60551 raw words (52106 effective words) took 0.0s, 1688797 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 15 : training on 60551 raw words (52092 effective words) took 0.0s, 1724828 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 16 : training on 60551 raw words (52088 effective words) took 0.0s, 1613287 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 17 : training on 60551 raw words (52085 effective words) took 0.0s, 1779842 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 18 : training on 60551 raw words (52108 effective words) took 0.0s, 1608863 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 19 : training on 60551 raw words (52063 effective words) took 0.0s, 1642723 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 20 : training on 60551 raw words (52136 effective words) took 0.0s, 1621868 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 21 : training on 60551 raw words (52056 effective words) took 0.0s, 1625087 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 22 : training on 60551 raw words (52041 effective words) took 0.0s, 1703794 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 23 : training on 60551 raw words (52033 effective words) took 0.0s, 1810132 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 24 : training on 60551 raw words (52079 effective words) took 0.0s, 1678912 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 25 : training on 60551 raw words (52080 effective words) took 0.0s, 1820275 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 26 : training on 60551 raw words (52079 effective words) took 0.0s, 1814097 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 27 : training on 60551 raw words (52084 effective words) took 0.0s, 1718504 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 28 : training on 60551 raw words (52098 effective words) took 0.0s, 1701418 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 29 : training on 60551 raw words (52050 effective words) took 0.0s, 1570015 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 30 : training on 60551 raw words (52043 effective words) took 0.0s, 1780033 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 31 : training on 60551 raw words (52134 effective words) took 0.0s, 1706081 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 32 : training on 60551 raw words (52051 effective words) took 0.0s, 1646260 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 33 : training on 60551 raw words (52033 effective words) took 0.0s, 1732061 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 34 : training on 60551 raw words (51962 effective words) took 0.0s, 1828684 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 35 : training on 60551 raw words (52170 effective words) took 0.0s, 1767237 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 36 : training on 60551 raw words (52116 effective words) took 0.0s, 1564357 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 37 : training on 60551 raw words (52087 effective words) took 0.0s, 1769806 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 38 : training on 60551 raw words (52037 effective words) took 0.0s, 1726917 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 39 : training on 60551 raw words (52076 effective words) took 0.0s, 1891286 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 40 : training on 60551 raw words (52070 effective words) took 0.0s, 1804397 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 41 : training on 60551 raw words (52155 effective words) took 0.0s, 1756211 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 42 : training on 60551 raw words (52030 effective words) took 0.0s, 1801877 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 43 : training on 60551 raw words (52107 effective words) took 0.0s, 1633361 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 44 : training on 60551 raw words (52092 effective words) took 0.0s, 1779732 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 45 : training on 60551 raw words (52039 effective words) took 0.0s, 1600738 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 46 : training on 60551 raw words (52026 effective words) took 0.0s, 1501947 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 47 : training on 60551 raw words (52069 effective words) took 0.0s, 1603279 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 48 : training on 60551 raw words (52034 effective words) took 0.0s, 1650765 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 49 : training on 60551 raw words (52078 effective words) took 0.0s, 1619603 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 50 : training on 60551 raw words (52142 effective words) took 0.0s, 1764232 effective words/s\n",
      "INFO : training on a 3027550 raw words (2603441 effective words) took 1.9s, 1372747 effective words/s\n",
      "INFO : precomputing L2-norms of word weight vectors\n",
      "WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : collected 5703 word types from a corpus of 56975 raw words and 6236 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : min_count=2 retains 3466 unique words (60% of original 5703, drops 2237)\n",
      "INFO : min_count=2 leaves 54738 word corpus (96% of original 56975, drops 2237)\n",
      "INFO : deleting the raw counts dictionary of 5703 items\n",
      "INFO : sample=0.001 downsamples 45 most-common words\n",
      "INFO : downsampling leaves estimated 48112 word corpus (87.9% of prior 54738)\n",
      "INFO : estimated required memory for 3466 words and 150 dimensions: 5892200 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : training model with 4 workers on 3466 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 56975 raw words (48087 effective words) took 0.0s, 1787175 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 56975 raw words (48123 effective words) took 0.0s, 1809805 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 56975 raw words (48114 effective words) took 0.0s, 1761169 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 56975 raw words (48034 effective words) took 0.0s, 1603826 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 56975 raw words (48181 effective words) took 0.0s, 1643371 effective words/s\n",
      "INFO : training on a 284875 raw words (240539 effective words) took 0.2s, 1416378 effective words/s\n",
      "WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "INFO : precomputing L2-norms of word weight vectors\n",
      "WARNING : Effective 'alpha' higher than previous training cycles\n",
      "INFO : training model with 4 workers on 3466 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=20\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 56975 raw words (48212 effective words) took 0.0s, 1623424 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 56975 raw words (48100 effective words) took 0.0s, 1772790 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 56975 raw words (48083 effective words) took 0.0s, 1634354 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 56975 raw words (48110 effective words) took 0.0s, 1628224 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 56975 raw words (48114 effective words) took 0.0s, 1546117 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 6 : training on 56975 raw words (48112 effective words) took 0.0s, 1334618 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : EPOCH - 7 : training on 56975 raw words (48198 effective words) took 0.0s, 1706383 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 8 : training on 56975 raw words (48097 effective words) took 0.0s, 1631510 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 9 : training on 56975 raw words (48063 effective words) took 0.0s, 1722471 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 10 : training on 56975 raw words (48033 effective words) took 0.0s, 1770718 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 11 : training on 56975 raw words (48008 effective words) took 0.0s, 1796337 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 12 : training on 56975 raw words (48031 effective words) took 0.0s, 1744830 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 13 : training on 56975 raw words (48156 effective words) took 0.0s, 1625060 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 14 : training on 56975 raw words (48207 effective words) took 0.0s, 1740495 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 15 : training on 56975 raw words (48130 effective words) took 0.0s, 1684078 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 16 : training on 56975 raw words (48209 effective words) took 0.0s, 1520439 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 17 : training on 56975 raw words (48242 effective words) took 0.0s, 1530437 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 18 : training on 56975 raw words (48120 effective words) took 0.0s, 1419966 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 19 : training on 56975 raw words (48141 effective words) took 0.0s, 1574672 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 20 : training on 56975 raw words (48078 effective words) took 0.0s, 1438755 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 21 : training on 56975 raw words (48140 effective words) took 0.0s, 1490188 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 22 : training on 56975 raw words (48024 effective words) took 0.0s, 1377743 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 23 : training on 56975 raw words (48119 effective words) took 0.0s, 1489174 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 24 : training on 56975 raw words (48117 effective words) took 0.0s, 1445972 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 25 : training on 56975 raw words (48089 effective words) took 0.0s, 1545807 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 26 : training on 56975 raw words (48194 effective words) took 0.0s, 1448274 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 27 : training on 56975 raw words (48124 effective words) took 0.0s, 1672986 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 28 : training on 56975 raw words (48069 effective words) took 0.0s, 1596922 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 29 : training on 56975 raw words (47971 effective words) took 0.0s, 1614645 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 30 : training on 56975 raw words (48021 effective words) took 0.0s, 1739336 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 31 : training on 56975 raw words (48152 effective words) took 0.0s, 1734268 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 32 : training on 56975 raw words (48118 effective words) took 0.0s, 1636276 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 33 : training on 56975 raw words (48165 effective words) took 0.0s, 1569709 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 34 : training on 56975 raw words (48001 effective words) took 0.0s, 1721516 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 35 : training on 56975 raw words (48123 effective words) took 0.0s, 1616844 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 36 : training on 56975 raw words (48145 effective words) took 0.0s, 1759951 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 37 : training on 56975 raw words (48139 effective words) took 0.0s, 1747171 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 38 : training on 56975 raw words (48199 effective words) took 0.0s, 1762662 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 39 : training on 56975 raw words (48131 effective words) took 0.0s, 1764662 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 40 : training on 56975 raw words (48120 effective words) took 0.0s, 1631194 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 41 : training on 56975 raw words (48194 effective words) took 0.0s, 1710086 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 42 : training on 56975 raw words (48115 effective words) took 0.0s, 1765388 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 43 : training on 56975 raw words (47988 effective words) took 0.0s, 1721972 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 44 : training on 56975 raw words (48021 effective words) took 0.0s, 1734424 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 45 : training on 56975 raw words (48146 effective words) took 0.0s, 1698670 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 46 : training on 56975 raw words (48145 effective words) took 0.0s, 1710077 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 47 : training on 56975 raw words (48077 effective words) took 0.0s, 1715372 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 48 : training on 56975 raw words (48145 effective words) took 0.0s, 1689324 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 49 : training on 56975 raw words (48139 effective words) took 0.0s, 1738488 effective words/s\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 50 : training on 56975 raw words (48190 effective words) took 0.0s, 1739915 effective words/s\n",
      "INFO : training on a 2848750 raw words (2405765 effective words) took 1.8s, 1330266 effective words/s\n",
      "INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "ot_model = get_model(ot_docs)\n",
    "ot_model.init_sims()\n",
    "\n",
    "nt_model = get_model(nt_docs)\n",
    "nt_model.init_sims()\n",
    "\n",
    "q_model = get_model(q_docs)\n",
    "q_model.init_sims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n"
     ]
    }
   ],
   "source": [
    "# INTERSECT THE MODELS ON THE COMMON VOCABULARY AND ALIGN.\n",
    "intersected_model = intersection_align_gensim([ot_model,nt_model,q_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REASSIGN NEW INTERSECTED MODELS\n",
    "ot_model = intersected_model[0]\n",
    "nt_model = intersected_model[1]\n",
    "q_model = intersected_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Neighborhood of associations of the word \"light\" in model1:\n",
      "darkness, lamp, shining, dark, preserved, clear, blind, path, cloud, feareth, step, pure, night, morning, unjust, shine, prayer, shadow, perfect, guide, righteousness, rising, walk, living, tarry\n",
      ">> Neighborhood of associations of the word \"light\" in model2:\n",
      "shine, darkness, lighten, shadow, sun, moon, dark, arise, shining, crooked, pain, chamber, marvel, folly, glorious, weight, suddenly, graf, heat, burning, star, burned, walk, lack, end\n",
      ">> Neighborhood of associations of the word \"light\" in model1:\n",
      "shine, darkness, lighten, shadow, sun, moon, dark, arise, shining, crooked, pain, chamber, marvel, folly, glorious, weight, suddenly, graf, heat, burning, star, burned, walk, lack, end\n",
      ">> Neighborhood of associations of the word \"light\" in model2:\n",
      "darkness, depth, lamp, glass, glorious, lead, star, wonder, walk, lowest, similitude, run, oil, olive, seed, knewest, sun, abide, garden, guide, parable, blessed, double, draweth, moon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:42: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
     ]
    }
   ],
   "source": [
    "# comparing old testament to new testament, then new testament to quran because of the chronology of the religions\n",
    "word = 'light'\n",
    "ot_to_nt = measure_semantic_shift_by_neighborhood(ot_model,nt_model,word,k=25,verbose=True)\n",
    "nt_to_q = measure_semantic_shift_by_neighborhood(nt_model,q_model,word,k=25,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33415612515597537, 0.4437865219092505)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ot_to_nt, nt_to_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "ot_X = ot_model[ot_model.wv.vocab]\n",
    "ot_reduced = pca.fit_transform(ot_X)\n",
    "\n",
    "nt_X = nt_model[nt_model.wv.vocab]\n",
    "nt_reduced = pca.fit_transform(nt_X)\n",
    "\n",
    "q_X = q_model[q_model.wv.vocab]\n",
    "q_reduced = pca.fit_transform(q_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_dict = {}\n",
    "wv_dict[\"ot\"] = {}\n",
    "wv_dict[\"nt\"] = {}\n",
    "wv_dict[\"q\"] = {}\n",
    "\n",
    "for i, word in enumerate(list(ot_model.wv.vocab)):\n",
    "    wv_dict[\"ot\"][word] = [float(ot_reduced[i][0]),float(ot_reduced[i][1])]\n",
    "    \n",
    "for i, word in enumerate(list(nt_model.wv.vocab)):\n",
    "    wv_dict[\"nt\"][word] = [float(nt_reduced[i][0]),float(nt_reduced[i][1])]\n",
    "    \n",
    "for i, word in enumerate(list(q_model.wv.vocab)):\n",
    "    wv_dict[\"q\"][word] = [float(q_reduced[i][0]),float(q_reduced[i][1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygon construction from Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import geometry as g\n",
    "from dxfwrite import DXFEngine as dxf\n",
    "from dxfwrite.const import CENTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['god', 'heaven', 'hell', 'love', 'hate', 'free', 'light', 'darkness', 'peace', 'war', 'life', 'death', 'man', 'woman', 'child', 'eat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n"
     ]
    }
   ],
   "source": [
    "topic_vecs = {}\n",
    "\n",
    "for t in topics:\n",
    "    topic_vecs[t] = {}\n",
    "\n",
    "    # go through each religion\n",
    "    for rel in wv_dict:\n",
    "        \n",
    "        model = None\n",
    "        if rel == 'ot':\n",
    "            model = ot_model\n",
    "        elif rel == 'nt':\n",
    "            model = nt_model\n",
    "        elif rel == 'q':\n",
    "            model = q_model\n",
    "            \n",
    "        most_sim = model.most_similar(positive=[t], topn=5)\n",
    "        topic_vecs[t][rel] = {\n",
    "            \"vec\": wv_dict[rel][t],\n",
    "            \"sim\": {}\n",
    "        }\n",
    "        \n",
    "        for w in most_sim:\n",
    "            wv = wv_dict[rel][w[0]]\n",
    "            topic_vecs[t][rel][\"sim\"][w[0]] = wv_dict[rel][w[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the vectors around each chosen word so every chosen word becomes (0,0)\n",
    "for t in topic_vecs:\n",
    "    rel_data = topic_vecs[t]\n",
    "    for d in rel_data:\n",
    "        vecs = rel_data[d]\n",
    "        \n",
    "        # this is what you'll normalize around\n",
    "        topic_vec = vecs['vec']\n",
    "        zero_vec = np.zeros(len(topic_vec))\n",
    "        \n",
    "        transform_vec = zero_vec - topic_vec\n",
    "        \n",
    "        closest = vecs['sim'] \n",
    "        for word in closest:\n",
    "            \n",
    "            # grab the original vector\n",
    "            og_sim_vec = closest[word]\n",
    "            \n",
    "            # transform the vector so it's centered around the current topic\n",
    "            transformed_sim_vec = og_sim_vec + transform_vec\n",
    "            \n",
    "            # reassign the transformed vector\n",
    "            closest[word] = list(transformed_sim_vec)\n",
    "        \n",
    "        # finally, reassign the original vector...\n",
    "        vecs['vec'] = list(zero_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'god': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'lord': [-0.07347187446430326, 0.38287484645843506],\n",
       "    'bless': [0.09206427587196231, 0.6182343810796738],\n",
       "    'worshipped': [-0.26532349782064557, 0.5583777129650116],\n",
       "    'quickly': [-0.17355159716680646, 0.6220635175704956],\n",
       "    'worship': [-0.027384320739656687, 0.6505152434110641]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'fellowship': [0.10126769542694092, -0.3102370798587799],\n",
       "    'salvation': [0.039955079555511475, -0.28650394082069397],\n",
       "    'true': [0.2374594658613205, -0.5676029026508331],\n",
       "    'glorify': [0.27052345871925354, -0.37814679741859436],\n",
       "    'dominion': [0.08419904112815857, -0.5259913802146912]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'worship': [-0.08062776923179626, 0.1715126633644104],\n",
       "    'idol': [0.2813589090947062, 0.2282082810997963],\n",
       "    'forbear': [0.20230995118618011, -0.037356674671173096],\n",
       "    'worshipper': [0.09774824976921082, -0.11156845092773438],\n",
       "    'taketh': [0.40792398154735565, 0.23016676306724548]}}},\n",
       " 'heaven': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'worshipped': [0.24439674615859985, -0.06195497512817383],\n",
       "    'air': [0.4352455958724022, 0.42201098799705505],\n",
       "    'established': [0.5029349653050303, -0.015966147184371948],\n",
       "    'left': [0.24833866953849792, -0.06750622391700745],\n",
       "    'room': [0.3028852492570877, 0.09083083271980286]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'lightning': [-0.065497487783432, -0.39699786901474],\n",
       "    'earthquake': [0.17988604307174683, -0.3164367228746414],\n",
       "    'fifth': [0.017020046710968018, -0.4087132588028908],\n",
       "    'earth': [-0.2219734787940979, -0.34007389284670353],\n",
       "    'east': [-0.035074204206466675, -0.1284204125404358]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'established': [-0.05160798132419586, -0.39470428228378296],\n",
       "    'creature': [0.06308573111891747, 0.15744230151176453],\n",
       "    'dominion': [0.08076133206486702, -0.04311323165893555],\n",
       "    'belongeth': [-0.07529996335506439, -0.11024938523769379],\n",
       "    'creator': [0.0008651688694953918, -0.05149435997009277]}}},\n",
       " 'hell': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'terror': [0.10536949336528778, -0.5463559776544571],\n",
       "    'lowest': [0.15345384180545807, -0.544804036617279],\n",
       "    'pit': [0.07758508622646332, -0.5665464401245117],\n",
       "    'descend': [-0.023152440786361694, -0.4923444390296936],\n",
       "    'grave': [0.18237363547086716, -0.7090659663081169]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'quenched': [-0.44232961907982826, 0.024879395961761475],\n",
       "    'raiment': [-0.21506720781326294, -0.002850770950317383],\n",
       "    'cast': [-0.2712830603122711, 0.3681938052177429],\n",
       "    'lot': [-0.24757613241672516, 0.27095940709114075],\n",
       "    'compass': [0.032981276512145996, 0.472714900970459]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'abode': [0.0252964049577713, -0.13729225331917405],\n",
       "    'misery': [0.2535906434059143, -0.20369291305541992],\n",
       "    'burn': [0.04472280293703079, -0.17711739242076874],\n",
       "    'continue': [0.12090452760457993, 0.1954927295446396],\n",
       "    'hinder': [-0.15387894213199615, -0.014568626880645752]}}},\n",
       " 'love': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'guide': [-0.0922166109085083, 0.18430938571691513],\n",
       "    'beloved': [-0.3663436248898506, 0.12937182933092117],\n",
       "    'hate': [-0.10541492700576782, 0.006647922098636627],\n",
       "    'establish': [-0.2465709149837494, -0.2013370469212532],\n",
       "    'remember': [-0.3542599454522133, -0.20875803381204605]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'kindness': [0.1939384937286377, -0.07433656603097916],\n",
       "    'neighbour': [0.35147398710250854, -0.13206416927278042],\n",
       "    'lady': [0.36900594830513, 0.06380422413349152],\n",
       "    'loveth': [0.17027434706687927, 0.08350245654582977],\n",
       "    'perfected': [0.22770750522613525, -0.10703762620687485]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'wound': [0.7592895366251469, -0.5296353101730347],\n",
       "    'tooth': [0.6643236167728901, -0.6591947972774506],\n",
       "    'hinder': [0.4981588274240494, -0.922574833035469],\n",
       "    'value': [0.3440035581588745, -0.749037891626358],\n",
       "    'freely': [0.603761799633503, -0.3650175929069519]}}},\n",
       " 'hate': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'ungodly': [-0.4656388461589813, 0.06594331562519073],\n",
       "    'condemn': [-0.2883265018463135, 0.01026010513305664],\n",
       "    'doer': [-0.34652620553970337, -0.13790448009967804],\n",
       "    'unrighteous': [-0.36813196539878845, 0.08154213428497314],\n",
       "    'hated': [-0.26216185092926025, -0.07935966551303864]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'despise': [0.39385324716567993, 0.2812814302742481],\n",
       "    'enemy': [0.7924741059541702, 0.09406483173370361],\n",
       "    'esteem': [0.4498160481452942, 0.10966353118419647],\n",
       "    'forgiving': [0.41308850049972534, 0.10073818266391754],\n",
       "    'exchange': [0.5406135022640228, 0.008618921041488647]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'prove': [0.8138287737965584, 0.27805009484291077],\n",
       "    'earnestly': [0.49737435579299927, 0.25754445791244507],\n",
       "    'doctrine': [0.8197942450642586, 0.18605253100395203],\n",
       "    'fellowship': [0.38831979036331177, 0.3931248188018799],\n",
       "    'forbear': [0.8312103301286697, 0.25585341453552246]}}},\n",
       " 'free': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'wage': [-0.40519411861896515, 0.5476025491952896],\n",
       "    'food': [-0.5601646155118942, 0.39265641011297703],\n",
       "    'tooth': [-0.45212025940418243, 0.6681414544582367],\n",
       "    'subjection': [-0.5766537114977837, 0.42496674321591854],\n",
       "    'labour': [-0.553797286003828, 0.4757058434188366]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'duty': [0.326732873916626, -0.5840830355882645],\n",
       "    'debt': [0.41197070479393005, -0.41285213083028793],\n",
       "    'offence': [0.2911095917224884, -0.3158772587776184],\n",
       "    'void': [0.2869519889354706, -0.48326198384165764],\n",
       "    'bond': [0.4719690680503845, -0.10449516773223877]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'want': [0.03446922078728676, -0.39920753240585327],\n",
       "    'manner': [-0.1359066143631935, -0.621383011341095],\n",
       "    'need': [0.014812342822551727, -0.4316304922103882],\n",
       "    'worthy': [-0.11555226147174835, -0.6489444673061371],\n",
       "    'feeding': [0.10085303336381912, -0.5990631878376007]}}},\n",
       " 'light': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'darkness': [-0.2842027097940445, 0.11023027542978525],\n",
       "    'lamp': [-0.228207066655159, 0.16525124851614237],\n",
       "    'shining': [-0.2863459438085556, 0.4575361842289567],\n",
       "    'dark': [-0.2305508479475975, 0.1197913745418191],\n",
       "    'preserved': [0.052264630794525146, -0.1334754740819335]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'shine': [-0.07323102653026581, -0.01744367554783821],\n",
       "    'darkness': [-0.005518332123756409, -0.08075955137610435],\n",
       "    'lighten': [-0.036932215094566345, 0.01239040493965149],\n",
       "    'shadow': [0.02059806138277054, -0.14851614460349083],\n",
       "    'sun': [0.3622463122010231, -0.30429091677069664]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'darkness': [0.16305693984031677, -0.3817069446668029],\n",
       "    'depth': [0.1430627405643463, -0.40676233172416687],\n",
       "    'lamp': [0.4613429605960846, -0.3894575163722038],\n",
       "    'glass': [0.40482398867607117, -0.360122200101614],\n",
       "    'glorious': [0.14624832570552826, -0.6040501594543457]}}},\n",
       " 'darkness': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'cloud': [0.06165599822998047, -0.11198219656944275],\n",
       "    'light': [0.36938459426164627, -0.20577627094462514],\n",
       "    'shadow': [0.06416401267051697, 0.05590856075286865],\n",
       "    'dark': [0.205174021422863, -0.0908796563744545],\n",
       "    'brightness': [0.06453374028205872, 0.14489305019378662]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'light': [-0.1468374766409397, 0.22834724001586437],\n",
       "    'shine': [-0.16744378954172134, 0.18862751871347427],\n",
       "    'pain': [0.03207160532474518, 0.11872005462646484],\n",
       "    'lighten': [-0.13114497810602188, 0.21846159920096397],\n",
       "    'sun': [0.26803354918956757, -0.09821972250938416]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'depth': [-0.2787454128265381, -0.018761353567242622],\n",
       "    'light': [-0.4696552902460098, 0.2002945225685835],\n",
       "    'lamp': [0.039534807205200195, -0.0014565382152795792],\n",
       "    'leaf': [-0.31112411618232727, -0.05698085017502308],\n",
       "    'lead': [-0.5366246774792671, -0.09258274175226688]}}},\n",
       " 'peace': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'sacrifice': [-0.16913569997996092, 0.036642223596572876],\n",
       "    'freely': [-0.06994131486862898, 0.2622593566775322],\n",
       "    'vow': [0.26572362054139376, 0.0858808159828186],\n",
       "    'idle': [0.1671985136345029, 0.47103870660066605],\n",
       "    'seeking': [0.07221457082778215, 0.2610558271408081]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'direct': [-0.12046051025390625, -0.38856539130210876],\n",
       "    'held': [0.3010217845439911, -0.0911954939365387],\n",
       "    'preserved': [-0.25429195165634155, -0.4377850592136383],\n",
       "    'declared': [0.13925595581531525, -0.04084581136703491],\n",
       "    'grant': [-0.20919370651245117, -0.40091729164123535]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'withdraw': [0.5353839956223965, -0.21979719400405884],\n",
       "    'entered': [0.20595231652259827, -0.2803699467331171],\n",
       "    'striving': [0.27373282611370087, -0.11018234491348267],\n",
       "    'faithful': [0.4337535388767719, -0.12258780002593994],\n",
       "    'strengthened': [0.20561519265174866, -0.40921981632709503]}}},\n",
       " 'war': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'battle': [-0.015541359782218933, 0.15311047434806824],\n",
       "    'band': [0.015868455171585083, 0.4159408137202263],\n",
       "    'mighty': [0.10403071343898773, 0.4023023215122521],\n",
       "    'fight': [0.029004395008087158, 0.10051769018173218],\n",
       "    'fighting': [0.2871426194906235, 0.43382714316248894]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'kindred': [0.481535941362381, 0.344561368227005],\n",
       "    'obtain': [-0.13594646751880646, 0.1307433545589447],\n",
       "    'fold': [0.32296060025691986, 0.29977763444185257],\n",
       "    'sawest': [0.3461008742451668, -0.09548203647136688],\n",
       "    'doer': [-0.19534672796726227, 0.0980335921049118]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'subdued': [0.2905109226703644, -0.5479196161031723],\n",
       "    'captive': [0.29576006531715393, -0.4927207827568054],\n",
       "    'fight': [0.10117188096046448, -0.5653392821550369],\n",
       "    'bind': [0.6298468634486198, -0.7309696972370148],\n",
       "    'prisoner': [0.36598508059978485, -0.6046327166259289]}}},\n",
       " 'life': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'desired': [0.034399520605802536, 0.2964427024126053],\n",
       "    'seek': [-0.08236771449446678, 0.12324884533882141],\n",
       "    'pleased': [0.061161670833826065, 0.02931523323059082],\n",
       "    'rest': [-0.15136798098683357, 0.10841406881809235],\n",
       "    'lose': [-0.041008430533111095, 0.5336621403694153]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'eternal': [0.011780768632888794, 0.03258821740746498],\n",
       "    'lose': [0.09190031886100769, -0.2691454030573368],\n",
       "    'victory': [0.33608361112419516, -0.21519436314702034],\n",
       "    'wage': [-0.1328166425228119, -0.22677547112107277],\n",
       "    'ransom': [0.3075039777904749, 0.2080725096166134]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'world': [0.17655383050441742, -0.3170856386423111],\n",
       "    'present': [0.2681467831134796, -0.40064334869384766],\n",
       "    'die': [0.4228997305035591, -0.36596980690956116],\n",
       "    'wealth': [0.22033295780420303, -0.16711640357971191],\n",
       "    'enjoy': [0.5495390295982361, -0.35693565011024475]}}},\n",
       " 'death': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'die': [0.06895487755537033, 0.007434189319610596],\n",
       "    'leper': [-0.14699290320277214, 0.2948143035173416],\n",
       "    'hid': [-0.055630747228860855, 0.24711691588163376],\n",
       "    'whosoever': [0.08510931953787804, 0.02207835018634796],\n",
       "    'worthy': [0.12710608914494514, 0.19133657962083817]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'taste': [0.15097691304981709, -0.06815719604492188],\n",
       "    'point': [0.26676177978515625, -0.27303776144981384],\n",
       "    'victory': [0.12996085511986166, -0.5399782210588455],\n",
       "    'sin': [-0.051191866397857666, -0.4077705852687359],\n",
       "    'power': [0.13679428258910775, -0.1877949833869934]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'purge': [0.2034352608025074, -0.016816550865769386],\n",
       "    'die': [0.2936897650361061, 0.15024135075509548],\n",
       "    'dead': [0.4807462990283966, 0.08006618358194828],\n",
       "    'slaughter': [0.25142722949385643, 0.20607138238847256],\n",
       "    'causeth': [0.347552552819252, 0.10998421721160412]}}},\n",
       " 'man': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'men': [-0.2364848293364048, 0.18634025752544403],\n",
       "    'husband': [0.20415497943758965, 0.3460083156824112],\n",
       "    'woman': [-0.06526720896363258, 0.20905499160289764],\n",
       "    'damsel': [0.09345994517207146, 0.23628222942352295],\n",
       "    'hearing': [0.2422616295516491, 0.4229552745819092]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'doeth': [-0.3985733352601528, -0.18570275604724884],\n",
       "    'lawful': [0.00903371162712574, -0.07097670435905457],\n",
       "    'ask': [-0.10647778585553169, -0.06766387820243835],\n",
       "    'goeth': [0.23114510253071785, -0.3784247934818268],\n",
       "    'spoil': [-0.24222875759005547, -0.44866323471069336]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'toucheth': [0.402554452419281, 0.0669984370470047],\n",
       "    'trouble': [0.2588460370898247, 0.12193816900253296],\n",
       "    'crieth': [0.39471276104450226, 0.062472596764564514],\n",
       "    'sow': [0.2996387481689453, -0.2923101484775543],\n",
       "    'young': [0.546546146273613, -0.2579462453722954]}}},\n",
       " 'woman': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'wife': [0.011358900927007198, -0.008613884449005127],\n",
       "    'damsel': [0.16678422689437866, 0.17453831434249878],\n",
       "    'husband': [0.27747926115989685, 0.284264400601387],\n",
       "    'mother': [0.11934343725442886, 0.2703967113047838],\n",
       "    'man': [0.044719213619828224, 0.11643911898136139]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'hair': [-0.14830413460731506, -0.4738473631441593],\n",
       "    'head': [-0.10760855674743652, -0.23543650284409523],\n",
       "    'husband': [-0.5561131983995438, 0.04364516958594322],\n",
       "    'issue': [-0.08835574984550476, -0.28807446733117104],\n",
       "    'subjection': [-0.5592336356639862, 0.12649386748671532]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'marry': [0.5199840813875198, -0.5804634094238281],\n",
       "    'husband': [0.5634679570794106, -0.7212431281805038],\n",
       "    'kill': [0.39549580216407776, -0.3045647144317627],\n",
       "    'adultery': [0.4164193272590637, -0.7737382724881172],\n",
       "    'pay': [0.40230001509189606, -0.44638878107070923]}}},\n",
       " 'child': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'married': [0.182375468313694, 0.4403056800365448],\n",
       "    'tribe': [0.08388583362102509, 0.27005136013031006],\n",
       "    'numbered': [0.03360304236412048, 0.28902992606163025],\n",
       "    'intend': [0.15251574106514454, 0.3733520209789276],\n",
       "    'judged': [0.12357830605469644, 0.39263007044792175]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'birth': [-0.007203884422779083, -0.32166634500026703],\n",
       "    'israel': [0.20616365224123, -0.0665164589881897],\n",
       "    'suck': [0.05664515309035778, -0.45689817517995834],\n",
       "    'young': [0.31654831022024155, -0.3325795531272888],\n",
       "    'overcome': [-0.2619701102375984, -0.46848108479753137]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'israel': [-0.06421692669391632, -0.4426542818546295],\n",
       "    'inheritance': [0.16345784813165665, 0.033173128962516785],\n",
       "    'sister': [0.20099595002830029, -0.1720608826726675],\n",
       "    'male': [0.33541111648082733, -0.12467754632234573],\n",
       "    'debt': [0.14009089395403862, 0.03582340478897095]}}},\n",
       " 'eat': {'ot': {'vec': [0.0, 0.0],\n",
       "   'sim': {'eaten': [0.19739140570163727, 0.48174337670207024],\n",
       "    'spent': [0.18730798363685608, 0.43845029175281525],\n",
       "    'taste': [0.1903718113899231, 0.5960291624069214],\n",
       "    'seest': [0.32820235937833786, 0.5194344371557236],\n",
       "    'meat': [0.19823390245437622, 0.33191196620464325]}},\n",
       "  'nt': {'vec': [0.0, 0.0],\n",
       "   'sim': {'meat': [-0.1623384729027748, -0.10235033929347992],\n",
       "    'manna': [0.1150553971529007, 0.08859646320343018],\n",
       "    'idol': [-0.22742165625095367, -0.037586554884910583],\n",
       "    'hunger': [0.039860114455223083, -0.23724843561649323],\n",
       "    'drink': [-0.07189184799790382, 0.026690885424613953]}},\n",
       "  'q': {'vec': [0.0, 0.0],\n",
       "   'sim': {'food': [-0.23324313759803772, -0.421385258436203],\n",
       "    'meat': [-0.3477651923894882, -0.3815411329269409],\n",
       "    'waste': [-0.21407222747802734, -0.356440007686615],\n",
       "    'drink': [0.017127394676208496, -0.3791031539440155],\n",
       "    'cattle': [-0.06308114528656006, -0.280320942401886]}}}}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "word {\n",
    "    \"ot\": [],\n",
    "    \"nt\"\n",
    "}\n",
    "\"\"\"\n",
    "polygon_data = {}\n",
    "\n",
    "for t in topic_vecs:\n",
    "    \n",
    "    rel_data = topic_vecs[t]\n",
    "    polygon_data[t] = {}\n",
    "    \n",
    "    for d in rel_data:\n",
    "        vecs = rel_data[d]\n",
    "        \n",
    "        ref_vec = vecs['vec']\n",
    "        sim_vecs = list(vecs['sim'].items())\n",
    "                \n",
    "        polygon_data[t][d] = {\n",
    "            \"poly\": g.Polygon([(v[1][0], v[1][1]) for v in sim_vecs]),\n",
    "            \"words\": [v[0] for v in sim_vecs]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating polygon / DXF data\n",
      "god\n",
      "heaven\n",
      "hell\n",
      "love\n",
      "hate\n",
      "free\n",
      "light\n",
      "darkness\n",
      "peace\n",
      "war\n",
      "life\n",
      "death\n",
      "man\n",
      "woman\n",
      "child\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating polygon / DXF data\")\n",
    "\n",
    "for topic in polygon_data:\n",
    "    \n",
    "    print(topic)\n",
    "    all_meta = polygon_data[topic]\n",
    "    \n",
    "    for rel in all_meta:\n",
    "        \n",
    "        # grab the specific religions meta data\n",
    "        rel_meta = all_meta[rel]\n",
    "        \n",
    "        # all the words\n",
    "        rel_words = rel_meta['words']\n",
    "        \n",
    "        # grab the convex hull and regular polygon data \n",
    "        rel_convex = list(rel_meta['poly'].convex_hull.exterior.coords)\n",
    "        rel_poly = list(rel_meta['poly'].exterior.coords)\n",
    "        \n",
    "        \n",
    "        #####################################\n",
    "        # DXF \n",
    "        #####################################\n",
    "        \n",
    "        # CONFIGURE THE FILE PATHS FOR SAVING\n",
    "        folder_path = '../data/analyzed/dxf/religion-specific/{}'.format(topic)\n",
    "\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.mkdir(folder_path)\n",
    "            \n",
    "        drawing = dxf.drawing('../data/analyzed/dxf/religion-specific/{}/{}-{}.dxf'.format(topic,topic,rel))\n",
    "        \n",
    "        line = dxf.polyline(linetype='DOT', layer ='INTERNAL')\n",
    "        outline = dxf.polyline(linetype='CONTINUOUS', layer = 'OUTLINE')\n",
    "        line.add_vertices(rel_poly)\n",
    "        outline.add_vertices(rel_convex)\n",
    "        \n",
    "        text_layer = dxf.layer('TEXT')\n",
    "        drawing.layers.add(text_layer)\n",
    "\n",
    "        # ADD THE TEXT\n",
    "        for p in zip(rel_words, rel_poly):\n",
    "            t = dxf.text(p[0], p[1], height=0.0125, rotation=0, layer = 'TEXT')\n",
    "            drawing.add(t)\n",
    "            \n",
    "        # Close the lines\n",
    "        outline.close()\n",
    "        line.close()\n",
    "        \n",
    "        drawing.add(outline)\n",
    "        drawing.add(line)\n",
    "        drawing.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
